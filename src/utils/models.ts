export interface ModelInfo {
  id: string;
  name: string;
  provider: string;
  available: boolean;
  maxTokens: number;
  contextLength: number;
  pricing: {
    input: number;
    output: number;
  };
  capabilities: string[];
  category: string;
  isLatest: boolean;
  notes?: string;
}

export const AVAILABLE_MODELS: ModelInfo[] = [
  // === OpenAI Models ===
  // === GPT-5 Models (Latest) ===
  {
    id: 'gpt-5',
    name: 'GPT-5',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 1.25, output: 10.0 },
    capabilities: ['text', 'reasoning', 'analysis', 'coding', 'agents'],
    category: 'text',
    isLatest: true,
    notes: 'The best model for coding and agentic tasks across domains'
  },
  {
    id: 'gpt-5-mini',
    name: 'GPT-5 mini',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.25, output: 2.0 },
    capabilities: ['text', 'reasoning', 'analysis', 'efficient'],
    category: 'text',
    isLatest: true,
    notes: 'A faster, cost-efficient version of GPT-5 for well-defined tasks'
  },
  {
    id: 'gpt-5-nano',
    name: 'GPT-5 nano',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.05, output: 0.4 },
    capabilities: ['text', 'fast', 'cost-effective'],
    category: 'text',
    isLatest: true,
    notes: 'Fastest, most cost-efficient version of GPT-5'
  },
  {
    id: 'gpt-5-pro',
    name: 'GPT-5 pro',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 2.50, output: 20.0 },
    capabilities: ['text', 'reasoning', 'analysis', 'coding', 'agents', 'premium'],
    category: 'text',
    isLatest: true,
    notes: 'Version of GPT-5 that produces smarter and more precise responses'
  },
  {
    id: 'gpt-5-codex',
    name: 'GPT-5-Codex',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 1.25, output: 10.0 },
    capabilities: ['code', 'programming', 'agents', 'coding'],
    category: 'code',
    isLatest: true,
    notes: 'A version of GPT-5 optimized for agentic coding in Codex'
  },
  {
    id: 'gpt-5-chat-latest',
    name: 'GPT-5 Chat',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 1.25, output: 10.0 },
    capabilities: ['text', 'chat', 'reasoning', 'analysis'],
    category: 'text',
    isLatest: true,
    notes: 'GPT-5 model used in ChatGPT (not recommended for API use)'
  },

  // === GPT-4o Models ===
  {
    id: 'gpt-4o-mini-2024-07-18',
    name: 'GPT-4o Mini',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.15, output: 0.6 },
    capabilities: ['text', 'vision', 'multimodal'],
    category: 'text',
    isLatest: true,
    notes: 'Latest GPT-4o Mini model with vision capabilities'
  },
  {
    id: 'gpt-4o',
    name: 'GPT-4o',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 2.5, output: 10.0 },
    capabilities: ['text', 'vision', 'multimodal'],
    category: 'text',
    isLatest: true,
    notes: 'Latest GPT-4o model with enhanced capabilities'
  },
  {
    id: 'gpt-4o-mini',
    name: 'GPT-4o Mini',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.15, output: 0.6 },
    capabilities: ['text', 'vision', 'multimodal'],
    category: 'text',
    isLatest: true,
    notes: 'GPT-4o Mini model with vision capabilities'
  },
  {
    id: 'gpt-4-turbo',
    name: 'GPT-4 Turbo',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 10.0, output: 30.0 },
    capabilities: ['text', 'vision', 'multimodal'],
    category: 'text',
    isLatest: false,
    notes: 'GPT-4 Turbo with vision capabilities'
  },
  {
    id: 'gpt-4',
    name: 'GPT-4',
    provider: 'OpenAI',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 30.0, output: 60.0 },
    capabilities: ['text'],
    category: 'text',
    isLatest: false,
    notes: 'GPT-4 base model'
  },
  {
    id: 'gpt-3.5-turbo',
    name: 'GPT-3.5 Turbo',
    provider: 'OpenAI',
    available: true,
    maxTokens: 16385,
    contextLength: 16385,
    pricing: { input: 0.5, output: 1.5 },
    capabilities: ['text'],
    category: 'text',
    isLatest: false,
    notes: 'GPT-3.5 Turbo model'
  },
  // === O-Series Models (Latest) ===
  {
    id: 'o3-pro',
    name: 'o3-pro',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 20.0, output: 80.0 },
    capabilities: ['text', 'reasoning', 'analysis', 'pro'],
    category: 'reasoning',
    isLatest: true,
    notes: 'Version of o3 with more compute for better responses'
  },
  {
    id: 'o3-deep-research',
    name: 'o3-deep-research',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 10.0, output: 40.0 },
    capabilities: ['text', 'research', 'analysis', 'deep'],
    category: 'research',
    isLatest: true,
    notes: 'Our most powerful deep research model'
  },
  {
    id: 'o4-mini',
    name: 'o4-mini',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 1.10, output: 4.40 },
    capabilities: ['text', 'reasoning', 'efficient'],
    category: 'reasoning',
    isLatest: true,
    notes: 'Fast, cost-efficient reasoning model, succeeded by GPT-5 mini'
  },
  {
    id: 'o4-mini-deep-research',
    name: 'o4-mini-deep-research',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 2.0, output: 8.0 },
    capabilities: ['text', 'research', 'analysis', 'efficient'],
    category: 'research',
    isLatest: true,
    notes: 'Faster, more affordable deep research model'
  },
  {
    id: 'o3',
    name: 'o3',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 2.0, output: 8.0 },
    capabilities: ['text', 'reasoning', 'analysis'],
    category: 'reasoning',
    isLatest: true,
    notes: 'Reasoning model for complex tasks, succeeded by GPT-5'
  },
  {
    id: 'o1-pro',
    name: 'o1-pro',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 150.0, output: 600.0 },
    capabilities: ['text', 'reasoning', 'analysis', 'premium'],
    category: 'reasoning',
    isLatest: true,
    notes: 'Version of o1 with more compute for better responses'
  },
  {
    id: 'o1',
    name: 'o1',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 15.0, output: 60.0 },
    capabilities: ['text', 'reasoning', 'analysis', 'advanced'],
    category: 'reasoning',
    isLatest: false,
    notes: 'Previous full o-series reasoning model'
  },
  // === Video Generation Models ===
  {
    id: 'sora-2',
    name: 'Sora 2',
    provider: 'OpenAI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.05, output: 0.05 },
    capabilities: ['video-generation', 'audio', 'synced-audio'],
    category: 'video',
    isLatest: true,
    notes: 'Flagship video generation with synced audio (priced per second)'
  },
  {
    id: 'sora-2-pro',
    name: 'Sora 2 Pro',
    provider: 'OpenAI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.10, output: 0.10 },
    capabilities: ['video-generation', 'audio', 'synced-audio', 'advanced'],
    category: 'video',
    isLatest: true,
    notes: 'Most advanced synced-audio video generation (priced per second)'
  },
  // === Image Generation Models ===
  {
    id: 'gpt-image-1',
    name: 'GPT Image 1',
    provider: 'OpenAI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.04, output: 0.04 },
    capabilities: ['image-generation', 'text-to-image'],
    category: 'image',
    isLatest: true,
    notes: 'State-of-the-art image generation model'
  },
  {
    id: 'gpt-image-1-mini',
    name: 'gpt-image-1-mini',
    provider: 'OpenAI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.02, output: 0.02 },
    capabilities: ['image-generation', 'text-to-image', 'cost-efficient'],
    category: 'image',
    isLatest: true,
    notes: 'A cost-efficient version of GPT Image 1'
  },
  // === Audio and Realtime Models ===
  {
    id: 'gpt-realtime',
    name: 'gpt-realtime',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 5.0, output: 20.0 },
    capabilities: ['text', 'audio', 'realtime', 'multimodal'],
    category: 'realtime',
    isLatest: true,
    notes: 'Model capable of realtime text and audio inputs and outputs'
  },
  {
    id: 'gpt-realtime-mini',
    name: 'gpt-realtime-mini',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.60, output: 2.40 },
    capabilities: ['text', 'audio', 'realtime', 'efficient'],
    category: 'realtime',
    isLatest: true,
    notes: 'A cost-efficient version of GPT Realtime'
  },
  {
    id: 'gpt-audio',
    name: 'gpt-audio',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 2.50, output: 10.0 },
    capabilities: ['text', 'audio', 'multimodal'],
    category: 'audio',
    isLatest: true,
    notes: 'For audio inputs and outputs with Chat Completions API'
  },
  {
    id: 'gpt-audio-mini',
    name: 'gpt-audio-mini',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.15, output: 0.60 },
    capabilities: ['text', 'audio', 'efficient'],
    category: 'audio',
    isLatest: true,
    notes: 'A cost-efficient version of GPT Audio'
  },
  // === Transcription Models ===
  {
    id: 'gpt-4o-transcribe',
    name: 'GPT-4o Transcribe',
    provider: 'OpenAI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.15, output: 0.15 },
    capabilities: ['audio', 'transcription', 'speech-to-text'],
    category: 'audio',
    isLatest: true,
    notes: 'Speech-to-text model powered by GPT-4o'
  },
  {
    id: 'gpt-4o-transcribe-diarize',
    name: 'GPT-4o Transcribe Diarize',
    provider: 'OpenAI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.20, output: 0.20 },
    capabilities: ['audio', 'transcription', 'speech-to-text', 'diarization'],
    category: 'audio',
    isLatest: true,
    notes: 'Transcription model that identifies who\'s speaking when'
  },
  {
    id: 'gpt-4o-mini-transcribe',
    name: 'GPT-4o mini Transcribe',
    provider: 'OpenAI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.10, output: 0.10 },
    capabilities: ['audio', 'transcription', 'speech-to-text', 'efficient'],
    category: 'audio',
    isLatest: true,
    notes: 'Speech-to-text model powered by GPT-4o mini'
  },
  {
    id: 'whisper-1',
    name: 'Whisper',
    provider: 'OpenAI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.006, output: 0.006 },
    capabilities: ['audio', 'transcription', 'speech-to-text', 'general-purpose'],
    category: 'audio',
    isLatest: true,
    notes: 'General-purpose speech recognition model (priced per minute)'
  },
  // === Text-to-Speech Models ===
  {
    id: 'gpt-4o-mini-tts',
    name: 'GPT-4o mini TTS',
    provider: 'OpenAI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.15, output: 0.15 },
    capabilities: ['audio', 'text-to-speech', 'tts'],
    category: 'audio',
    isLatest: true,
    notes: 'Text-to-speech model powered by GPT-4o mini'
  },
  {
    id: 'tts-1',
    name: 'TTS-1',
    provider: 'OpenAI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.015, output: 0.015 },
    capabilities: ['audio', 'text-to-speech', 'tts', 'fast'],
    category: 'audio',
    isLatest: true,
    notes: 'Text-to-speech model optimized for speed (priced per 1K characters)'
  },
  {
    id: 'tts-1-hd',
    name: 'TTS-1 HD',
    provider: 'OpenAI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.030, output: 0.030 },
    capabilities: ['audio', 'text-to-speech', 'tts', 'high-quality'],
    category: 'audio',
    isLatest: true,
    notes: 'Text-to-speech model optimized for quality (priced per 1K characters)'
  },
  // === Open-Weight Models ===
  {
    id: 'gpt-oss-120b',
    name: 'gpt-oss-120b',
    provider: 'OpenAI',
    available: true,
    maxTokens: 131072,
    contextLength: 131072,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['text', 'open-source', 'open-weight'],
    category: 'text',
    isLatest: true,
    notes: 'Most powerful open-weight model, fits into an H100 GPU. Licensed under Apache 2.0'
  },
  {
    id: 'gpt-oss-20b',
    name: 'gpt-oss-20b',
    provider: 'OpenAI',
    available: true,
    maxTokens: 131072,
    contextLength: 131072,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['text', 'open-source', 'open-weight', 'low-latency'],
    category: 'text',
    isLatest: true,
    notes: 'Medium-sized open-weight model for low latency. Licensed under Apache 2.0'
  },
  {
    id: 'gpt-4.1',
    name: 'GPT-4.1',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 2.0, output: 8.0 },
    capabilities: ['text', 'analysis', 'enhanced'],
    category: 'text',
    isLatest: true,
    notes: 'Smartest non-reasoning model'
  },
  {
    id: 'gpt-4.1-mini',
    name: 'GPT-4.1 mini',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.40, output: 1.60 },
    capabilities: ['text', 'analysis', 'efficient'],
    category: 'text',
    isLatest: true,
    notes: 'Smaller, faster version of GPT-4.1'
  },
  {
    id: 'gpt-4.1-nano',
    name: 'GPT-4.1 nano',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.10, output: 0.40 },
    capabilities: ['text', 'fast', 'cost-effective'],
    category: 'text',
    isLatest: true,
    notes: 'Fastest, most cost-efficient version of GPT-4.1'
  },

  // === Anthropic Models ===
  {
    id: 'claude-opus-4-1-20250805',
    name: 'Claude Opus 4.1',
    provider: 'Anthropic',
    available: true,
    maxTokens: 32000,
    contextLength: 200000,
    pricing: { input: 15.0, output: 75.0 },
    capabilities: ['text', 'vision', 'multimodal', 'reasoning', 'extended-thinking', 'multilingual'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Most capable and intelligent Claude model yet - superior reasoning and advanced coding (Mar 2025 cutoff)'
  },
  {
    id: 'claude-opus-4-20250514',
    name: 'Claude Opus 4',
    provider: 'Anthropic',
    available: true,
    maxTokens: 32000,
    contextLength: 200000,
    pricing: { input: 15.0, output: 75.0 },
    capabilities: ['text', 'vision', 'multimodal', 'reasoning', 'extended-thinking', 'multilingual'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Previous flagship model with very high intelligence and capability (Mar 2025 cutoff)'
  },
  {
    id: 'claude-sonnet-4-20250514',
    name: 'Claude Sonnet 4',
    provider: 'Anthropic',
    available: true,
    maxTokens: 64000,
    contextLength: 200000,
    pricing: { input: 3.0, output: 15.0 },
    capabilities: ['text', 'vision', 'multimodal', 'reasoning', 'extended-thinking', 'multilingual'],
    category: 'multimodal',
    isLatest: false,
    notes: 'High-performance model with exceptional reasoning (Mar 2025 cutoff, 1M context beta available). Use Claude Sonnet 4.5 for latest version'
  },
  {
    id: 'claude-3-7-sonnet-20250219',
    name: 'Claude Sonnet 3.7',
    provider: 'Anthropic',
    available: true,
    maxTokens: 64000,
    contextLength: 200000,
    pricing: { input: 3.0, output: 15.0 },
    capabilities: ['text', 'vision', 'multimodal', 'reasoning', 'extended-thinking', 'multilingual'],
    category: 'multimodal',
    isLatest: false,
    notes: 'High-performance model with early extended thinking (Oct 2024 cutoff, 64k output). Deprecated - use Claude Sonnet 4.5 instead'
  },
  {
    id: 'claude-3-5-sonnet-20241022',
    name: 'Claude Sonnet 3.5 v2',
    provider: 'Anthropic',
    available: true,
    maxTokens: 8192,
    contextLength: 200000,
    pricing: { input: 3.0, output: 15.0 },
    capabilities: ['text', 'vision', 'multimodal', 'reasoning', 'multilingual'],
    category: 'multimodal',
    isLatest: false,
    notes: 'Upgraded Claude 3.5 Sonnet (Apr 2024 cutoff, 8k output)'
  },
  {
    id: 'claude-sonnet-4-5',
    name: 'Claude Sonnet 4.5',
    provider: 'Anthropic',
    available: true,
    maxTokens: 200000,
    contextLength: 200000,
    pricing: { input: 3.0, output: 15.0 },
    capabilities: ['text', 'vision', 'multimodal', 'reasoning', 'extended-thinking', 'multilingual'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Latest Claude Sonnet model with enhanced capabilities and 1M context window support (beta)'
  },
  {
    id: 'claude-haiku-4-5',
    name: 'Claude Haiku 4.5',
    provider: 'Anthropic',
    available: true,
    maxTokens: 200000,
    contextLength: 200000,
    pricing: { input: 1.0, output: 5.0 },
    capabilities: ['text', 'vision', 'multimodal', 'multilingual'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Latest Claude Haiku model with improved performance and capabilities'
  },
  {
    id: 'claude-3-5-haiku-20241022',
    name: 'Claude Haiku 3.5',
    provider: 'Anthropic',
    available: true,
    maxTokens: 8192,
    contextLength: 200000,
    pricing: { input: 0.8, output: 4.0 },
    capabilities: ['text', 'vision', 'multimodal', 'multilingual'],
    category: 'multimodal',
    isLatest: false,
    notes: 'Fastest Claude model (July 2024 cutoff, 8k output)'
  },

  // === Google AI Models ===
  // === Gemini 2.5 Models (Latest) ===
  {
    id: 'gemini-2.5-pro',
    name: 'Gemini 2.5 Pro',
    provider: 'Google AI',
    available: true,
    maxTokens: 2000000,
    contextLength: 2000000,
    pricing: { input: 1.25, output: 10.0 },
    capabilities: ['text', 'multimodal', 'reasoning', 'coding', 'complex-problems', 'thinking'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Our state-of-the-art thinking model, capable of reasoning over complex problems in code, math, and STEM, as well as analyzing large datasets, codebases, and documents using long context'
  },
  {
    id: 'gemini-2.5-flash',
    name: 'Gemini 2.5 Flash',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 0.3, output: 2.5 },
    capabilities: ['text', 'image', 'video', 'multimodal', 'reasoning', 'thinking', 'live-api', 'agents'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Our best model in terms of price-performance, offering well-rounded capabilities. Best for large scale processing, low-latency, high volume tasks that require thinking, and agentic use cases'
  },
  {
    id: 'gemini-2.5-flash-lite-preview',
    name: 'Gemini 2.5 Flash-Lite Preview',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 0.1, output: 0.4 },
    capabilities: ['text', 'image', 'video', 'multimodal', 'reasoning', 'thinking', 'high-throughput'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Our fastest flash model optimized for cost-efficiency and high throughput. Features 1M token context window and multimodal input'
  },
  {
    id: 'gemini-2.5-flash-lite',
    name: 'Gemini 2.5 Flash-Lite',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 0.1, output: 0.4 },
    capabilities: ['text', 'image', 'video', 'multimodal', 'reasoning', 'thinking', 'high-throughput'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Our fastest flash model optimized for cost-efficiency and high throughput (stable version)'
  },
  {
    id: 'gemini-2.5-flash-audio',
    name: 'Gemini 2.5 Flash Audio',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 1.0, output: 2.5 },
    capabilities: ['audio', 'multimodal', 'audio-input'],
    category: 'audio',
    isLatest: true,
    notes: 'Gemini 2.5 Flash with audio input capabilities'
  },
  {
    id: 'gemini-2.5-flash-lite-audio-preview',
    name: 'Gemini 2.5 Flash-Lite Audio Preview',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 0.5, output: 0.4 },
    capabilities: ['audio', 'multimodal', 'audio-input', 'high-throughput'],
    category: 'audio',
    isLatest: true,
    notes: 'Gemini 2.5 Flash-Lite with audio input capabilities'
  },
  {
    id: 'gemini-2.5-flash-native-audio',
    name: 'Gemini 2.5 Flash Native Audio',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 0.5, output: 2.0 },
    capabilities: ['audio', 'multimodal', 'native-audio'],
    category: 'audio',
    isLatest: true,
    notes: 'Native audio model optimized for higher quality audio outputs'
  },
  {
    id: 'gemini-2.5-flash-native-audio-output',
    name: 'Gemini 2.5 Flash Native Audio Output',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 3.0, output: 12.0 },
    capabilities: ['audio', 'multimodal', 'native-audio', 'audio-output'],
    category: 'audio',
    isLatest: true,
    notes: 'Native audio model with audio output capabilities'
  },
  {
    id: 'gemini-2.5-flash-preview-tts',
    name: 'Gemini 2.5 Flash Preview TTS',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 0.5, output: 10.0 },
    capabilities: ['text-to-speech', 'audio', 'tts'],
    category: 'audio',
    isLatest: true,
    notes: '2.5 Flash TTS model optimized for price-performant, low-latency speech generation'
  },
  {
    id: 'gemini-2.5-pro-preview-tts',
    name: 'Gemini 2.5 Pro Preview TTS',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 1.0, output: 20.0 },
    capabilities: ['text-to-speech', 'audio', 'tts'],
    category: 'audio',
    isLatest: true,
    notes: '2.5 Pro TTS model optimized for powerful, low-latency speech generation'
  },

  // === Gemini 2.0 Models ===
  {
    id: 'gemini-2.0-flash',
    name: 'Gemini 2.0 Flash',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 0.1, output: 0.4 },
    capabilities: ['text', 'image', 'video', 'multimodal', 'agents', 'next-generation'],
    category: 'multimodal',
    isLatest: false,
    notes: 'Our second generation workhorse model, with a 1 million token context window'
  },
  {
    id: 'gemini-2.0-flash-lite',
    name: 'Gemini 2.0 Flash-Lite',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 0.075, output: 0.3 },
    capabilities: ['text', 'multimodal', 'cost-efficient', 'low-latency'],
    category: 'multimodal',
    isLatest: false,
    notes: 'Our second generation small workhorse model, with a 1 million token context window'
  },
  {
    id: 'gemini-2.0-flash-audio',
    name: 'Gemini 2.0 Flash Audio',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 0.7, output: 0.4 },
    capabilities: ['audio', 'multimodal', 'audio-input'],
    category: 'audio',
    isLatest: false,
    notes: 'Gemini 2.0 Flash with audio input capabilities'
  },

  // === Gemini 1.5 Models ===
  {
    id: 'gemini-1.5-flash',
    name: 'Gemini 1.5 Flash',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 0.075, output: 0.3 },
    capabilities: ['text', 'image', 'video', 'multimodal'],
    category: 'multimodal',
    isLatest: false,
    notes: 'Fastest multimodal model for diverse, repetitive tasks'
  },
  {
    id: 'gemini-1.5-flash-large-context',
    name: 'Gemini 1.5 Flash Large Context',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 0.15, output: 0.6 },
    capabilities: ['text', 'image', 'video', 'multimodal', 'large-context'],
    category: 'multimodal',
    isLatest: false,
    notes: 'Gemini 1.5 Flash with large context pricing (>128k tokens)'
  },
  {
    id: 'gemini-1.5-flash-8b',
    name: 'Gemini 1.5 Flash-8B',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 0.0375, output: 0.15 },
    capabilities: ['text', 'image', 'video', 'multimodal', 'efficient'],
    category: 'multimodal',
    isLatest: false,
    notes: 'Smallest model for lower intelligence use cases'
  },
  {
    id: 'gemini-1.5-flash-8b-large-context',
    name: 'Gemini 1.5 Flash-8B Large Context',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 0.075, output: 0.3 },
    capabilities: ['text', 'image', 'video', 'multimodal', 'efficient', 'large-context'],
    category: 'multimodal',
    isLatest: false,
    notes: 'Gemini 1.5 Flash-8B with large context pricing (>128k tokens)'
  },
  {
    id: 'gemini-1.5-pro',
    name: 'Gemini 1.5 Pro',
    provider: 'Google AI',
    available: true,
    maxTokens: 2000000,
    contextLength: 2000000,
    pricing: { input: 1.25, output: 5.0 },
    capabilities: ['text', 'code', 'reasoning', 'multimodal'],
    category: 'text',
    isLatest: false,
    notes: 'Highest intelligence Gemini 1.5 series model with 2M context'
  },
  {
    id: 'gemini-1.5-pro-large-context',
    name: 'Gemini 1.5 Pro Large Context',
    provider: 'Google AI',
    available: true,
    maxTokens: 2000000,
    contextLength: 2000000,
    pricing: { input: 2.5, output: 10.0 },
    capabilities: ['text', 'code', 'reasoning', 'multimodal', 'large-context'],
    category: 'text',
    isLatest: false,
    notes: 'Gemini 1.5 Pro with large context pricing (>128k tokens)'
  },

  // === Gemma Models (Open Source) ===
  {
    id: 'gemma-3n',
    name: 'Gemma 3n',
    provider: 'Google AI',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['text', 'open-source', 'multimodal', '140-languages', 'mobile-optimized'],
    category: 'text',
    isLatest: true,
    notes: 'The latest open models, designed for efficient execution on low-resource devices, capable of multimodal input (text, image, video, audio), and trained with data in over 140 spoken languages'
  },
  {
    id: 'gemma-3',
    name: 'Gemma 3',
    provider: 'Google AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['text', 'open-source', 'multimodal', '140-languages', 'wide-variety-tasks'],
    category: 'text',
    isLatest: true,
    notes: 'The third generation of our open models, featuring the ability to solve a wide variety of tasks with text and image input, support for over 140 languages, and long 128K context window'
  },
  {
    id: 'gemma-2',
    name: 'Gemma 2',
    provider: 'Google AI',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['text', 'open-source', 'text-generation', 'summarization', 'extraction'],
    category: 'text',
    isLatest: false,
    notes: 'The second generation of our open models featuring text generation, summarization, and extraction'
  },
  {
    id: 'gemma',
    name: 'Gemma',
    provider: 'Google AI',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['text', 'open-source', 'text-generation', 'summarization', 'extraction', 'lightweight'],
    category: 'text',
    isLatest: false,
    notes: 'A small-sized, lightweight open model supporting text generation, summarization, and extraction'
  },

  // === Specialized Gemma Models ===
  {
    id: 'shieldgemma-2',
    name: 'ShieldGemma 2',
    provider: 'Google AI',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['text', 'open-source', 'safety-evaluation', 'instruction-tuned'],
    category: 'safety',
    isLatest: true,
    notes: 'Instruction tuned models for evaluating the safety of text and images against a set of defined safety policies'
  },
  {
    id: 'paligemma',
    name: 'PaliGemma',
    provider: 'Google AI',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['text', 'open-source', 'vision-language', 'siglip', 'gemma'],
    category: 'vision-language',
    isLatest: true,
    notes: 'Our open vision-language model that combines SigLIP and Gemma'
  },
  {
    id: 'codegemma',
    name: 'CodeGemma',
    provider: 'Google AI',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['text', 'open-source', 'coding', 'fill-in-middle', 'code-generation', 'mathematical-reasoning'],
    category: 'coding',
    isLatest: true,
    notes: 'Powerful, lightweight open model that can perform a variety of coding tasks like fill-in-the-middle code completion, code generation, natural language understanding, mathematical reasoning, and instruction following'
  },
  {
    id: 'txgemma',
    name: 'TxGemma',
    provider: 'Google AI',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['text', 'open-source', 'therapeutic', 'predictions', 'classifications', 'efficient-training'],
    category: 'therapeutic',
    isLatest: true,
    notes: 'Generates predictions, classifications or text based on therapeutic related data and can be used to efficiently build AI models for therapeutic-related tasks with less data and less compute'
  },
  {
    id: 'medgemma',
    name: 'MedGemma',
    provider: 'Google AI',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['text', 'open-source', 'medical', 'medical-comprehension', 'variants'],
    category: 'medical',
    isLatest: true,
    notes: 'Collection of Gemma 3 variants that are trained for performance on medical text and image comprehension'
  },
  {
    id: 'medsiglip',
    name: 'MedSigLIP',
    provider: 'Google AI',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['text', 'open-source', 'medical', 'medical-images', 'embedding-space'],
    category: 'medical',
    isLatest: true,
    notes: 'SigLIP variant that is trained to encode medical images and text into a common embedding space'
  },
  {
    id: 't5gemma',
    name: 'T5Gemma',
    provider: 'Google AI',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['text', 'open-source', 'encoder-decoder', 'research', 'lightweight', 'powerful'],
    category: 'research',
    isLatest: true,
    notes: 'A family of lightweight yet powerful encoder-decoder research models from Google'
  },

  // === Embeddings Models ===
  {
    id: 'text-embedding-004',
    name: 'Text Embedding 004',
    provider: 'Google AI',
    available: true,
    maxTokens: 2048,
    contextLength: 2048,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['embedding', 'semantic-search', 'classification', 'clustering'],
    category: 'embedding',
    isLatest: true,
    notes: 'State-of-the-art text embedding model for semantic search, classification, clustering, and similar tasks'
  },
  {
    id: 'multimodal-embeddings',
    name: 'Multimodal Embeddings',
    provider: 'Google AI',
    available: true,
    maxTokens: 2048,
    contextLength: 2048,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['embedding', 'multimodal', 'image-classification', 'image-search'],
    category: 'embedding',
    isLatest: true,
    notes: 'Generates vectors based on images, which can be used for downstream tasks like image classification, image search, and more'
  },

  // === Imagen Models (Image Generation) ===
  {
    id: 'imagen-4-generation',
    name: 'Imagen 4 for Generation',
    provider: 'Google AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.04, output: 0.04 },
    capabilities: ['image-generation', 'text-to-image', 'higher-quality'],
    category: 'image',
    isLatest: true,
    notes: 'Use text prompts to generate novel images with higher quality than our previous image generation models'
  },
  {
    id: 'imagen-4-fast-generation',
    name: 'Imagen 4 for Fast Generation',
    provider: 'Google AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.04, output: 0.04 },
    capabilities: ['image-generation', 'text-to-image', 'higher-quality', 'lower-latency'],
    category: 'image',
    isLatest: true,
    notes: 'Use text prompts to generate novel images with higher quality and lower latency than our previous image generation models'
  },
  {
    id: 'imagen-4-ultra-generation',
    name: 'Imagen 4 for Ultra Generation',
    provider: 'Google AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.06, output: 0.06 },
    capabilities: ['image-generation', 'text-to-image', 'higher-quality', 'better-prompt-adherence'],
    category: 'image',
    isLatest: true,
    notes: 'Use text prompts to generate novel images with higher quality and better prompt adherence than our previous image generation models'
  },
  {
    id: 'imagen-3-generation',
    name: 'Imagen 3 for Generation',
    provider: 'Google AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.03, output: 0.03 },
    capabilities: ['image-generation', 'text-to-image'],
    category: 'image',
    isLatest: false,
    notes: 'Use text prompts to generate novel images'
  },
  {
    id: 'imagen-3-editing-customization',
    name: 'Imagen 3 for Editing and Customization',
    provider: 'Google AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.03, output: 0.03 },
    capabilities: ['image-generation', 'text-to-image', 'image-editing', 'customization', 'mask-editing'],
    category: 'image',
    isLatest: false,
    notes: 'Use text prompts to edit existing input images, or parts of an image with a mask or generate new images based upon the context provided by input reference images'
  },
  {
    id: 'imagen-3-fast-generation',
    name: 'Imagen 3 for Fast Generation',
    provider: 'Google AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.03, output: 0.03 },
    capabilities: ['image-generation', 'text-to-image', 'lower-latency'],
    category: 'image',
    isLatest: false,
    notes: 'Use text prompts to generate novel images with lower latency than our other image generation models'
  },
  {
    id: 'imagen-captioning-vqa',
    name: 'Imagen for Captioning & VQA',
    provider: 'Google AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.03, output: 0.03 },
    capabilities: ['image-generation', 'text-to-image', 'image-editing', 'mask-editing', 'captioning', 'vqa'],
    category: 'image',
    isLatest: false,
    notes: 'Use text prompts to generate novel images, edit existing ones, edit parts of an image with a mask and more'
  },

  // === Veo Models (Video Generation) ===
  {
    id: 'veo-2',
    name: 'Veo 2',
    provider: 'Google AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.35, output: 0.35 },
    capabilities: ['video-generation', 'text-to-video', 'image-to-video', 'higher-quality'],
    category: 'video',
    isLatest: true,
    notes: 'Use text prompts and images to generate novel videos with higher quality than our previous video generation model (priced per second)'
  },
  {
    id: 'veo-3',
    name: 'Veo 3',
    provider: 'Google AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.35, output: 0.35 },
    capabilities: ['video-generation', 'text-to-video', 'image-to-video', 'higher-quality'],
    category: 'video',
    isLatest: true,
    notes: 'Use text prompts and images to generate novel videos with higher quality than our previous video generation model (priced per second)'
  },
  {
    id: 'veo-3-fast',
    name: 'Veo 3 Fast',
    provider: 'Google AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.35, output: 0.35 },
    capabilities: ['video-generation', 'text-to-video', 'image-to-video', 'higher-quality', 'lower-latency'],
    category: 'video',
    isLatest: true,
    notes: 'Use text prompts and images to generate novel videos with higher quality and lower latency than our previous video generation model (priced per second)'
  },

  // === Preview Models ===
  {
    id: 'virtual-try-on',
    name: 'Virtual Try-On',
    provider: 'Google AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['image-generation', 'virtual-try-on', 'clothing'],
    category: 'image',
    isLatest: true,
    notes: 'Generate images of people wearing clothing products (preview model, free tier only)'
  },
  {
    id: 'veo-3-preview',
    name: 'Veo 3 Preview',
    provider: 'Google AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.35, output: 0.35 },
    capabilities: ['video-generation', 'text-to-video', 'image-to-video', 'higher-quality', 'preview'],
    category: 'video',
    isLatest: true,
    notes: 'Use text prompts and images to generate novel videos with higher quality than our previous video generation model (preview model, priced per second)'
  },
  {
    id: 'veo-3-fast-preview',
    name: 'Veo 3 Fast Preview',
    provider: 'Google AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.35, output: 0.35 },
    capabilities: ['video-generation', 'text-to-video', 'image-to-video', 'higher-quality', 'lower-latency', 'preview'],
    category: 'video',
    isLatest: true,
    notes: 'Use text prompts and images to generate novel videos with higher quality and lower latency than our previous video generation model (preview model, priced per second)'
  },

  // === Legacy Models for Backward Compatibility ===
  {
    id: 'gemini-1.0-pro',
    name: 'Gemini 1.0 Pro',
    provider: 'Google AI',
    available: true,
    maxTokens: 32768,
    contextLength: 32768,
    pricing: { input: 1.0, output: 2.0 },
    capabilities: ['text', 'vision', 'multimodal'],
    category: 'text',
    isLatest: false,
    notes: 'Earlier generation Gemini model (legacy)'
  },
  {
    id: 'gemini-1.0-pro-vision',
    name: 'Gemini 1.0 Pro Vision',
    provider: 'Google AI',
    available: true,
    maxTokens: 32768,
    contextLength: 32768,
    pricing: { input: 1.0, output: 2.0 },
    capabilities: ['text', 'vision', 'multimodal'],
    category: 'text',
    isLatest: false,
    notes: 'Earlier generation Gemini model with vision capabilities (legacy)'
  },

  // === AWS Bedrock Models ===
  {
    id: 'ai21.jamba-1-5-large-v1:0',
    name: 'Jamba 1.5 Large (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 256000,
    contextLength: 256000,
    pricing: { input: 2.0, output: 8.0 },
    capabilities: ['text', 'long-context'],
    category: 'text',
    isLatest: true,
    notes: 'AI21 Labs Jamba 1.5 Large via AWS Bedrock'
  },
  {
    id: 'ai21.jamba-1-5-mini-v1:0',
    name: 'Jamba 1.5 Mini (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 256000,
    contextLength: 256000,
    pricing: { input: 0.2, output: 0.4 },
    capabilities: ['text', 'long-context', 'efficient'],
    category: 'text',
    isLatest: true,
    notes: 'AI21 Labs Jamba 1.5 Mini via AWS Bedrock'
  },
  {
    id: 'amazon.nova-micro-v1:0',
    name: 'Amazon Nova Micro (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.035, output: 0.14 },
    capabilities: ['text', 'ultra-fast', 'cost-effective'],
    category: 'text',
    isLatest: true,
    notes: 'Amazon Nova Micro via AWS Bedrock'
  },
  {
    id: 'amazon.nova-lite-v1:0',
    name: 'Amazon Nova Lite (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 300000,
    contextLength: 300000,
    pricing: { input: 0.06, output: 0.24 },
    capabilities: ['text', 'multimodal', 'fast'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Amazon Nova Lite via AWS Bedrock'
  },
  {
    id: 'amazon.nova-pro-v1:0',
    name: 'Amazon Nova Pro (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 300000,
    contextLength: 300000,
    pricing: { input: 0.8, output: 3.2 },
    capabilities: ['text', 'multimodal', 'reasoning'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Amazon Nova Pro via AWS Bedrock'
  },
  {
    id: 'amazon.nova-premier-v1:0',
    name: 'Amazon Nova Premier (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 300000,
    contextLength: 300000,
    pricing: { input: 2.5, output: 12.5 },
    capabilities: ['text', 'multimodal', 'advanced-reasoning'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Amazon Nova Premier via AWS Bedrock'
  },
  {
    id: 'amazon.nova-canvas-v1:0',
    name: 'Amazon Nova Canvas (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 4096,
    contextLength: 4096,
    pricing: { input: 0.04, output: 0.04 },
    capabilities: ['image-generation'],
    category: 'image',
    isLatest: true,
    notes: 'Amazon Nova Canvas via AWS Bedrock - image generation model'
  },
  {
    id: 'amazon.nova-reel-v1:0',
    name: 'Amazon Nova Reel (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 4096,
    contextLength: 4096,
    pricing: { input: 0.08, output: 0.08 },
    capabilities: ['video-generation'],
    category: 'video',
    isLatest: true,
    notes: 'Amazon Nova Reel via AWS Bedrock - video generation model'
  },
  {
    id: 'amazon.nova-sonic-v1:0',
    name: 'Amazon Nova Sonic (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 300000,
    contextLength: 300000,
    pricing: { input: 3.4, output: 13.6 },
    capabilities: ['speech', 'multimodal', 'native-audio'],
    category: 'audio',
    isLatest: true,
    notes: 'Amazon Nova Sonic via AWS Bedrock - speech model'
  },
  {
    id: 'amazon.titan-text-express-v1',
    name: 'Amazon Titan Text Express (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 8000,
    contextLength: 8000,
    pricing: { input: 0.8, output: 1.6 },
    capabilities: ['text'],
    category: 'text',
    isLatest: true,
    notes: 'Amazon Titan Text Express via AWS Bedrock'
  },
  {
    id: 'amazon.titan-text-lite-v1',
    name: 'Amazon Titan Text Lite (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 4000,
    contextLength: 4000,
    pricing: { input: 0.3, output: 0.4 },
    capabilities: ['text'],
    category: 'text',
    isLatest: true,
    notes: 'Amazon Titan Text Lite via AWS Bedrock'
  },
  {
    id: 'amazon.titan-embed-text-v2:0',
    name: 'Amazon Titan Text Embeddings V2 (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.02, output: 0.02 },
    capabilities: ['embedding'],
    category: 'embedding',
    isLatest: true,
    notes: 'Amazon Titan Text Embeddings V2 via AWS Bedrock'
  },
  {
    id: 'anthropic.claude-opus-4-1-20250805-v1:0',
    name: 'Claude Opus 4.1 (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 32000,
    contextLength: 200000,
    pricing: { input: 15.0, output: 75.0 },
    capabilities: ['text', 'vision', 'multimodal', 'reasoning', 'extended-thinking', 'multilingual'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Claude Opus 4.1 via AWS Bedrock - most capable and intelligent Claude model yet'
  },
  {
    id: 'anthropic.claude-opus-4-20250514-v1:0',
    name: 'Claude Opus 4 (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 32000,
    contextLength: 200000,
    pricing: { input: 15.0, output: 75.0 },
    capabilities: ['text', 'vision', 'multimodal', 'reasoning', 'extended-thinking', 'multilingual'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Claude Opus 4 via AWS Bedrock - previous flagship model'
  },
  {
    id: 'anthropic.claude-sonnet-4-5-v1:0',
    name: 'Claude Sonnet 4.5 (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 200000,
    contextLength: 200000,
    pricing: { input: 3.0, output: 15.0 },
    capabilities: ['text', 'vision', 'multimodal', 'reasoning', 'extended-thinking', 'multilingual'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Claude Sonnet 4.5 on AWS Bedrock - latest Claude Sonnet model with enhanced capabilities and 1M context window support (beta)'
  },
  {
    id: 'anthropic.claude-haiku-4-5-v1:0',
    name: 'Claude Haiku 4.5 (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 200000,
    contextLength: 200000,
    pricing: { input: 1.0, output: 5.0 },
    capabilities: ['text', 'vision', 'multimodal', 'multilingual'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Claude Haiku 4.5 on AWS Bedrock - latest Claude Haiku model with improved performance'
  },
  {
    id: 'anthropic.claude-sonnet-4-20250514-v1:0',
    name: 'Claude Sonnet 4 (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 64000,
    contextLength: 200000,
    pricing: { input: 3.0, output: 15.0 },
    capabilities: ['text', 'vision', 'multimodal', 'reasoning', 'extended-thinking', 'multilingual'],
    category: 'multimodal',
    isLatest: false,
    notes: 'Claude Sonnet 4 via AWS Bedrock - high-performance model with exceptional reasoning'
  },
  {
    id: 'anthropic.claude-3-7-sonnet-20250219-v1:0',
    name: 'Claude Sonnet 3.7 (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 64000,
    contextLength: 200000,
    pricing: { input: 3.0, output: 15.0 },
    capabilities: ['text', 'vision', 'multimodal', 'reasoning', 'extended-thinking', 'multilingual'],
    category: 'multimodal',
    isLatest: false,
    notes: 'Claude Sonnet 3.7 via AWS Bedrock - high-performance model with early extended thinking. Deprecated - use Claude Sonnet 4.5 instead'
  },
  {
    id: 'anthropic.claude-3-5-sonnet-20241022-v1:0',
    name: 'Claude Sonnet 3.5 v2 (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 8192,
    contextLength: 200000,
    pricing: { input: 3.0, output: 15.0 },
    capabilities: ['text', 'vision', 'multimodal', 'reasoning', 'multilingual'],
    category: 'multimodal',
    isLatest: false,
    notes: 'Claude Sonnet 3.5 v2 via AWS Bedrock - upgraded version'
  },
  {
    id: 'anthropic.claude-3-5-haiku-20241022-v1:0',
    name: 'Claude Haiku 3.5 (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 8192,
    contextLength: 200000,
    pricing: { input: 0.8, output: 4.0 },
    capabilities: ['text', 'vision', 'multimodal', 'multilingual'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Claude Haiku 3.5 via AWS Bedrock - fastest Claude model'
  },
  {
    id: 'meta.llama3-70b-instruct-v1:0',
    name: 'Llama 3 70B Instruct (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.59, output: 0.79 },
    capabilities: ['text', 'instruction-following'],
    category: 'text',
    isLatest: true,
    notes: 'Meta Llama 3 70B Instruct via AWS Bedrock'
  },
  {
    id: 'meta.llama3-8b-instruct-v1:0',
    name: 'Llama 3 8B Instruct (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.05, output: 0.10 },
    capabilities: ['text', 'instruction-following', 'fast'],
    category: 'text',
    isLatest: true,
    notes: 'Meta Llama 3 8B Instruct via AWS Bedrock'
  },
  {
    id: 'meta.llama3-2-11b-instruct-v1:0',
    name: 'Llama 3.2 11B Instruct (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.16, output: 0.16 },
    capabilities: ['text', 'instruction-following', 'vision'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Meta Llama 3.2 11B Instruct via AWS Bedrock'
  },
  {
    id: 'meta.llama3-2-90b-instruct-v1:0',
    name: 'Llama 3.2 90B Instruct (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.72, output: 0.72 },
    capabilities: ['text', 'instruction-following', 'vision'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Meta Llama 3.2 90B Instruct via AWS Bedrock'
  },
  {
    id: 'meta.llama4-scout-17b-instruct-v1:0',
    name: 'Llama 4 Scout 17B Instruct (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.17, output: 0.66 },
    capabilities: ['text', 'instruction-following', 'vision'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Meta Llama 4 Scout 17B Instruct via AWS Bedrock'
  },
  {
    id: 'meta.llama4-maverick-17b-instruct-v1:0',
    name: 'Llama 4 Maverick 17B Instruct (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.24, output: 0.97 },
    capabilities: ['text', 'instruction-following', 'vision'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Meta Llama 4 Maverick 17B Instruct via AWS Bedrock'
  },
  {
    id: 'mistral.mistral-7b-instruct-v0:2',
    name: 'Mistral 7B Instruct (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 32768,
    contextLength: 32768,
    pricing: { input: 0.15, output: 0.45 },
    capabilities: ['text', 'instruction-following', 'fast'],
    category: 'text',
    isLatest: true,
    notes: 'Mistral 7B Instruct via AWS Bedrock'
  },
  {
    id: 'mistral.mixtral-8x7b-instruct-v0:1',
    name: 'Mixtral 8x7B Instruct (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 32768,
    contextLength: 32768,
    pricing: { input: 0.24, output: 0.72 },
    capabilities: ['text', 'instruction-following', 'mixture-of-experts'],
    category: 'text',
    isLatest: true,
    notes: 'Mistral Mixtral 8x7B Instruct via AWS Bedrock'
  },
  {
    id: 'mistral.mistral-large-2402-v1:0',
    name: 'Mistral Large (24.02) (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 32768,
    contextLength: 32768,
    pricing: { input: 6.50, output: 25.00 },
    capabilities: ['text', 'instruction-following'],
    category: 'text',
    isLatest: true,
    notes: 'Mistral Large via AWS Bedrock'
  },
  {
    id: 'mistral.mistral-small-2402-v1:0',
    name: 'Mistral Small (24.02) (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 32768,
    contextLength: 32768,
    pricing: { input: 2.00, output: 6.00 },
    capabilities: ['text', 'instruction-following'],
    category: 'text',
    isLatest: true,
    notes: 'Mistral Small via AWS Bedrock'
  },
  {
    id: 'mistral.pixtral-large-2502-v1:0',
    name: 'Pixtral Large (25.02) (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 2.0, output: 6.0 },
    capabilities: ['vision', 'multimodal', 'reasoning'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Mistral Pixtral Large via AWS Bedrock'
  },
  {
    id: 'cohere.command-r-plus-v1:0',
    name: 'Command R+ (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 2.5, output: 10.0 },
    capabilities: ['text', 'multilingual', 'enterprise'],
    category: 'text',
    isLatest: true,
    notes: 'Cohere Command R+ via AWS Bedrock - updated pricing'
  },
  {
    id: 'cohere.command-r-v1:0',
    name: 'Command R (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.15, output: 0.6 },
    capabilities: ['text', 'multilingual', 'rag', 'tools'],
    category: 'text',
    isLatest: true,
    notes: 'Cohere Command R via AWS Bedrock - updated pricing'
  },
  {
    id: 'cohere.embed-english-v3',
    name: 'Embed English v3 (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 512,
    contextLength: 512,
    pricing: { input: 0.1, output: 0.1 },
    capabilities: ['embedding'],
    category: 'embedding',
    isLatest: true,
    notes: 'Cohere Embed English v3 via AWS Bedrock'
  },
  {
    id: 'cohere.embed-multilingual-v3',
    name: 'Embed Multilingual v3 (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 512,
    contextLength: 512,
    pricing: { input: 0.1, output: 0.1 },
    capabilities: ['embedding', 'multilingual'],
    category: 'embedding',
    isLatest: true,
    notes: 'Cohere Embed Multilingual v3 via AWS Bedrock'
  },
  // Latest Cohere Models
  {
    id: 'command-a-03-2025',
    name: 'Command A',
    provider: 'Cohere',
    available: true,
    maxTokens: 256000,
    contextLength: 256000,
    pricing: { input: 2.5, output: 10.0 },
    capabilities: ['text', 'agentic', 'multilingual', 'human-evaluations'],
    category: 'text',
    isLatest: true,
    notes: 'Most performant model to date, excelling at tool use, agents, RAG, and multilingual use cases'
  },
  {
    id: 'command-r7b-12-2024',
    name: 'Command R7B',
    provider: 'Cohere',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.0375, output: 0.15 },
    capabilities: ['text', 'rag', 'tool-use', 'agents'],
    category: 'text',
    isLatest: true,
    notes: 'Small, fast update delivered in December 2024, excels at RAG, tool use, and complex reasoning'
  },
  {
    id: 'command-a-reasoning-08-2025',
    name: 'Command A Reasoning',
    provider: 'Cohere',
    available: true,
    maxTokens: 256000,
    contextLength: 256000,
    pricing: { input: 2.5, output: 10.0 },
    capabilities: ['text', 'reasoning', 'agentic', 'multilingual'],
    category: 'text',
    isLatest: true,
    notes: 'First reasoning model, able to think before generating output for nuanced problem-solving and agent-based tasks in 23 languages'
  },
  {
    id: 'command-a-vision-07-2025',
    name: 'Command A Vision',
    provider: 'Cohere',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 2.5, output: 10.0 },
    capabilities: ['text', 'vision', 'multimodal', 'enterprise'],
    category: 'multimodal',
    isLatest: true,
    notes: 'First model capable of processing images, excelling in enterprise use cases like charts, graphs, diagrams, table understanding, OCR, and object detection'
  },
  {
    id: 'command-r-plus-04-2024',
    name: 'Command R+',
    provider: 'Cohere',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 2.5, output: 10.0 },
    capabilities: ['text', 'enterprise', 'rag', 'tools', 'multilingual'],
    category: 'text',
    isLatest: true,
    notes: 'Instruction-following conversational model for complex RAG workflows and multi-step tool use'
  },
  {
    id: 'command-r-08-2024',
    name: 'Command R (08-2024)',
    provider: 'Cohere',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.15, output: 0.6 },
    capabilities: ['text', 'rag', 'tools', 'agents'],
    category: 'text',
    isLatest: true,
    notes: 'Update of Command R model delivered in August 2024'
  },
  {
    id: 'command-r-03-2024',
    name: 'Command R (03-2024)',
    provider: 'Cohere',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.15, output: 0.6 },
    capabilities: ['text', 'rag', 'tools', 'agents'],
    category: 'text',
    isLatest: false,
    notes: 'Instruction-following conversational model for complex workflows like code generation, RAG, tool use, and agents'
  },
  {
    id: 'command',
    name: 'Command',
    provider: 'Cohere',
    available: true,
    maxTokens: 4096,
    contextLength: 4096,
    pricing: { input: 0.15, output: 0.6 },
    capabilities: ['text', 'conversational'],
    category: 'text',
    isLatest: false,
    notes: 'Instruction-following conversational model for language tasks with high quality and reliability'
  },
  {
    id: 'command-nightly',
    name: 'Command Nightly',
    provider: 'Cohere',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.15, output: 0.6 },
    capabilities: ['text', 'experimental', 'nightly'],
    category: 'text',
    isLatest: false,
    notes: 'Latest experimental version, not recommended for production use'
  },
  {
    id: 'command-light',
    name: 'Command Light',
    provider: 'Cohere',
    available: true,
    maxTokens: 4096,
    contextLength: 4096,
    pricing: { input: 0.15, output: 0.6 },
    capabilities: ['text', 'lightweight', 'fast'],
    category: 'text',
    isLatest: false,
    notes: 'Smaller, faster version of command, almost as capable but much faster'
  },
  {
    id: 'command-light-nightly',
    name: 'Command Light Nightly',
    provider: 'Cohere',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.15, output: 0.6 },
    capabilities: ['text', 'lightweight', 'experimental', 'nightly'],
    category: 'text',
    isLatest: false,
    notes: 'Latest experimental version of command-light, not recommended for production use'
  },
  {
    id: 'rerank-v3.5',
    name: 'Rerank v3.5',
    provider: 'Cohere',
    available: true,
    maxTokens: 4096,
    contextLength: 4096,
    pricing: { input: 2.0, output: 2.0 },
    capabilities: ['rerank', 'semantic-search', 'retrieval'],
    category: 'rerank',
    isLatest: true,
    notes: 'Provides powerful semantic boost to search quality of any keyword or vector search system, $2.00 per 1K searches'
  },
  {
    id: 'rerank-english-v3.0',
    name: 'Rerank English v3.0',
    provider: 'Cohere',
    available: true,
    maxTokens: 4096,
    contextLength: 4096,
    pricing: { input: 2.0, output: 2.0 },
    capabilities: ['rerank', 'semantic-search', 'english'],
    category: 'rerank',
    isLatest: true,
    notes: 'English language document and semi-structured data reranking model'
  },
  {
    id: 'rerank-multilingual-v3.0',
    name: 'Rerank Multilingual v3.0',
    provider: 'Cohere',
    available: true,
    maxTokens: 4096,
    contextLength: 4096,
    pricing: { input: 2.0, output: 2.0 },
    capabilities: ['rerank', 'semantic-search', 'multilingual'],
    category: 'rerank',
    isLatest: true,
    notes: 'Multilingual document and semi-structured data reranking model'
  },
  {
    id: 'embed-v4.0',
    name: 'Embed v4.0',
    provider: 'Cohere',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.12, output: 0.12 },
    capabilities: ['embedding', 'multimodal', 'semantic-search', 'rag'],
    category: 'embedding',
    isLatest: true,
    notes: 'Leading multimodal embedding model for text and images, acts as intelligent retrieval engine for semantic search and RAG systems'
  },
  {
    id: 'embed-english-v3.0',
    name: 'Embed English v3.0',
    provider: 'Cohere',
    available: true,
    maxTokens: 512,
    contextLength: 512,
    pricing: { input: 0.1, output: 0.1 },
    capabilities: ['embedding', 'english'],
    category: 'embedding',
    isLatest: true,
    notes: 'English-only embedding model for text classification and embeddings'
  },
  {
    id: 'embed-english-light-v3.0',
    name: 'Embed English Light v3.0',
    provider: 'Cohere',
    available: true,
    maxTokens: 512,
    contextLength: 512,
    pricing: { input: 0.1, output: 0.1 },
    capabilities: ['embedding', 'english', 'lightweight'],
    category: 'embedding',
    isLatest: true,
    notes: 'Smaller, faster version of embed-english-v3.0, almost as capable but much faster'
  },
  {
    id: 'embed-multilingual-v3.0',
    name: 'Embed Multilingual v3.0',
    provider: 'Cohere',
    available: true,
    maxTokens: 512,
    contextLength: 512,
    pricing: { input: 0.1, output: 0.1 },
    capabilities: ['embedding', 'multilingual'],
    category: 'embedding',
    isLatest: true,
    notes: 'Multilingual embedding model for classification and embeddings in multiple languages'
  },
  {
    id: 'embed-multilingual-light-v3.0',
    name: 'Embed Multilingual Light v3.0',
    provider: 'Cohere',
    available: true,
    maxTokens: 512,
    contextLength: 512,
    pricing: { input: 0.1, output: 0.1 },
    capabilities: ['embedding', 'multilingual', 'lightweight'],
    category: 'embedding',
    isLatest: true,
    notes: 'Smaller, faster version of embed-multilingual-v3.0, almost as capable but much faster'
  },
  {
    id: 'c4ai-aya-expanse-8b',
    name: 'Aya Expanse 8B',
    provider: 'Cohere',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.15, output: 0.6 },
    capabilities: ['text', 'multilingual', '23-languages'],
    category: 'text',
    isLatest: true,
    notes: 'Highly performant 8B multilingual model designed to rival monolingual performance, serves 23 languages'
  },
  {
    id: 'c4ai-aya-expanse-32b',
    name: 'Aya Expanse 32B',
    provider: 'Cohere',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.15, output: 0.6 },
    capabilities: ['text', 'multilingual', '23-languages'],
    category: 'text',
    isLatest: true,
    notes: 'Highly performant 32B multilingual model designed to rival monolingual performance, serves 23 languages'
  },
  {
    id: 'c4ai-aya-vision-8b',
    name: 'Aya Vision 8B',
    provider: 'Cohere',
    available: true,
    maxTokens: 16384,
    contextLength: 16384,
    pricing: { input: 0.15, output: 0.6 },
    capabilities: ['text', 'vision', 'multimodal', 'multilingual'],
    category: 'multimodal',
    isLatest: true,
    notes: 'State-of-the-art multimodal model excelling at language, text, and image capabilities, 8B variant focused on low latency'
  },
  {
    id: 'c4ai-aya-vision-32b',
    name: 'Aya Vision 32B',
    provider: 'Cohere',
    available: true,
    maxTokens: 16384,
    contextLength: 16384,
    pricing: { input: 0.15, output: 0.6 },
    capabilities: ['text', 'vision', 'multimodal', 'multilingual', '23-languages'],
    category: 'multimodal',
    isLatest: true,
    notes: 'State-of-the-art multimodal model excelling at language, text, and image capabilities, 32B variant focused on state-of-art multilingual performance'
  },
  {
    id: 'deepseek.r1-v1:0',
    name: 'DeepSeek-R1 (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 64000,
    contextLength: 64000,
    pricing: { input: 1.35, output: 5.4 },
    capabilities: ['text', 'reasoning', 'cot'],
    category: 'reasoning',
    isLatest: true,
    notes: 'DeepSeek-R1 reasoning model via AWS Bedrock'
  },
  {
    id: 'stability.stable-diffusion-xl-v1:0',
    name: 'Stable Diffusion XL 1.0 (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 77,
    contextLength: 77,
    pricing: { input: 0.18, output: 0.18 },
    capabilities: ['image-generation', 'creative-content'],
    category: 'image-generation',
    isLatest: true,
    notes: 'Stability AI Stable Diffusion XL via AWS Bedrock'
  },
  {
    id: 'twelvelabs.pegasus-1-2-v1:0',
    name: 'Pegasus v1.2 (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['text', 'video', 'multimodal'],
    category: 'multimodal',
    isLatest: true,
    notes: 'TwelveLabs Pegasus v1.2 via AWS Bedrock - video understanding model'
  },
  {
    id: 'twelvelabs.marengo-embed-2-7-v1:0',
    name: 'Marengo Embed v2.7 (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['embedding', 'multimodal'],
    category: 'embedding',
    isLatest: true,
    notes: 'TwelveLabs Marengo Embed v2.7 via AWS Bedrock - multimodal embeddings'
  },
  
  // === Mistral AI Models ===
  // Premier Models
  {
    id: 'mistral-medium-2508',
    name: 'Mistral Medium 3.1',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.4, output: 2.0 },
    capabilities: ['text', 'multimodal', 'vision', 'analysis', 'reasoning', 'enterprise'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Our frontier-class multimodal model released August 2025. Improving tone and performance.'
  },
  {
    id: 'mistral-medium-latest',
    name: 'Mistral Medium 3.1',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.4, output: 2.0 },
    capabilities: ['text', 'multimodal', 'vision', 'analysis', 'reasoning', 'enterprise'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Our frontier-class multimodal model released August 2025. Improving tone and performance.'
  },
  {
    id: 'magistral-medium-2509',
    name: 'Magistral Medium 1.2',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 40000,
    contextLength: 40000,
    pricing: { input: 2.0, output: 5.0 },
    capabilities: ['text', 'reasoning', 'thinking', 'domain-specific', 'multilingual', 'multimodal'],
    category: 'reasoning',
    isLatest: true,
    notes: 'Our frontier-class multimodal reasoning model released September 2025 (v25.09).'
  },
  {
    id: 'magistral-medium-latest',
    name: 'Magistral Medium 1.2',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 40000,
    contextLength: 40000,
    pricing: { input: 2.0, output: 5.0 },
    capabilities: ['text', 'reasoning', 'thinking', 'domain-specific', 'multilingual', 'multimodal'],
    category: 'reasoning',
    isLatest: true,
    notes: 'Our frontier-class multimodal reasoning model released September 2025 (v25.09).'
  },
  {
    id: 'magistral-medium-2507',
    name: 'Magistral Medium 1.1',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 40000,
    contextLength: 40000,
    pricing: { input: 2.0, output: 5.0 },
    capabilities: ['text', 'reasoning', 'thinking', 'domain-specific', 'multilingual'],
    category: 'reasoning',
    isLatest: false,
    notes: 'Our frontier-class reasoning model released July 2025 (v25.07). Deprecated October 31, 2025, retirement November 30, 2025. Use Magistral Medium 1.2 instead.'
  },
  {
    id: 'codestral-2508',
    name: 'Codestral 2508',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 256000,
    contextLength: 256000,
    pricing: { input: 0.3, output: 0.9 },
    capabilities: ['code', 'programming', 'multilingual-code', 'fill-in-middle', 'code-correction', 'test-generation'],
    category: 'code',
    isLatest: true,
    notes: 'Our cutting-edge language model for coding released end of July 2025, specializes in low-latency, high-frequency tasks.'
  },
  {
    id: 'codestral-latest',
    name: 'Codestral 2508',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 256000,
    contextLength: 256000,
    pricing: { input: 0.3, output: 0.9 },
    capabilities: ['code', 'programming', 'multilingual-code', 'fill-in-middle', 'code-correction', 'test-generation'],
    category: 'code',
    isLatest: true,
    notes: 'Our cutting-edge language model for coding released end of July 2025, specializes in low-latency, high-frequency tasks.'
  },
  {
    id: 'voxtral-mini-2507',
    name: 'Voxtral Mini Transcribe',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.1, output: 0.1 },
    capabilities: ['audio', 'transcription', 'efficient'],
    category: 'audio',
    isLatest: true,
    notes: 'An efficient audio input model, fine-tuned and optimized for transcription purposes only.'
  },
  {
    id: 'voxtral-mini-latest',
    name: 'Voxtral Mini Transcribe',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.1, output: 0.1 },
    capabilities: ['audio', 'transcription', 'efficient'],
    category: 'audio',
    isLatest: true,
    notes: 'An efficient audio input model, fine-tuned and optimized for transcription purposes only.'
  },
  {
    id: 'devstral-medium-2507',
    name: 'Devstral Medium',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.4, output: 2.0 },
    capabilities: ['code', 'agents', 'advanced-coding', 'codebase-exploration', 'multi-file-editing'],
    category: 'code',
    isLatest: true,
    notes: 'An enterprise grade text model that excels at using tools to explore codebases, editing multiple files and power software engineering agents.'
  },
  {
    id: 'devstral-medium-latest',
    name: 'Devstral Medium',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.4, output: 2.0 },
    capabilities: ['code', 'agents', 'advanced-coding', 'codebase-exploration', 'multi-file-editing'],
    category: 'code',
    isLatest: true,
    notes: 'An enterprise grade text model that excels at using tools to explore codebases, editing multiple files and power software engineering agents.'
  },
  {
    id: 'mistral-ocr-2505',
    name: 'Mistral OCR 2505',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 1.0, output: 3.0 },
    capabilities: ['ocr', 'document-understanding', 'annotations', 'text-extraction'],
    category: 'document',
    isLatest: true,
    notes: 'Our OCR service powering our Document AI stack that enables our users to extract interleaved text and images.'
  },
  {
    id: 'mistral-ocr-latest',
    name: 'Mistral OCR 2505',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 1.0, output: 3.0 },
    capabilities: ['ocr', 'document-understanding', 'annotations', 'text-extraction'],
    category: 'document',
    isLatest: true,
    notes: 'Our OCR service powering our Document AI stack that enables our users to extract interleaved text and images.'
  },
  {
    id: 'mistral-large-2411',
    name: 'Mistral Large 2.1',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 2.0, output: 6.0 },
    capabilities: ['text', 'reasoning', 'complex-tasks', 'high-complexity'],
    category: 'text',
    isLatest: true,
    notes: 'Our top-tier large model for high-complexity tasks with the latest version released November 2024.'
  },
  {
    id: 'mistral-large-latest',
    name: 'Mistral Large 2.1',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 2.0, output: 6.0 },
    capabilities: ['text', 'reasoning', 'complex-tasks', 'high-complexity'],
    category: 'text',
    isLatest: true,
    notes: 'Our top-tier large model for high-complexity tasks with the latest version released November 2024.'
  },
  {
    id: 'pixtral-large-2411',
    name: 'Pixtral Large',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 2.0, output: 6.0 },
    capabilities: ['vision', 'multimodal', 'reasoning', 'frontier-class'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Our first frontier-class multimodal model released November 2024.'
  },
  {
    id: 'pixtral-large-latest',
    name: 'Pixtral Large',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 2.0, output: 6.0 },
    capabilities: ['vision', 'multimodal', 'reasoning', 'frontier-class'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Our first frontier-class multimodal model released November 2024.'
  },
  {
    id: 'mistral-small-2407',
    name: 'Mistral Small 2',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 32000,
    contextLength: 32000,
    pricing: { input: 0.1, output: 0.3 },
    capabilities: ['text', 'multimodal', 'multilingual', 'open-source'],
    category: 'multimodal',
    isLatest: false,
    notes: 'Our updated small version, released September 2024.'
  },
  {
    id: 'mistral-embed',
    name: 'Mistral Embed',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.1, output: 0.1 },
    capabilities: ['embedding', 'text', 'semantic'],
    category: 'embedding',
    isLatest: true,
    notes: 'Our state-of-the-art semantic for extracting representation of text extracts.'
  },
  {
    id: 'codestral-embed-2505',
    name: 'Codestral Embed',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.15, output: 0.15 },
    capabilities: ['embedding', 'code', 'semantic'],
    category: 'embedding',
    isLatest: true,
    notes: 'Our state-of-the-art semantic for extracting representation of code extracts.'
  },
  {
    id: 'mistral-moderation-2411',
    name: 'Mistral Moderation 24.11',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 32000,
    contextLength: 32000,
    pricing: { input: 0.1, output: 0.1 },
    capabilities: ['moderation', 'classification', 'harmful-content-detection'],
    category: 'moderation',
    isLatest: true,
    notes: 'Our moderation service that enables our users to detect harmful text content.'
  },
  {
    id: 'mistral-moderation-latest',
    name: 'Mistral Moderation 24.11',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 32000,
    contextLength: 32000,
    pricing: { input: 0.1, output: 0.1 },
    capabilities: ['moderation', 'classification', 'harmful-content-detection'],
    category: 'moderation',
    isLatest: true,
    notes: 'Our moderation service that enables our users to detect harmful text content.'
  },
  
  // Open Models
  {
    id: 'magistral-small-2509',
    name: 'Magistral Small 1.2',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 40000,
    contextLength: 40000,
    pricing: { input: 0.5, output: 1.5 },
    capabilities: ['text', 'reasoning', 'thinking', 'domain-specific', 'multilingual', 'multimodal'],
    category: 'reasoning',
    isLatest: true,
    notes: 'Our small multimodal reasoning model released September 2025 (v25.09).'
  },
  {
    id: 'magistral-small-latest',
    name: 'Magistral Small 1.2',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 40000,
    contextLength: 40000,
    pricing: { input: 0.5, output: 1.5 },
    capabilities: ['text', 'reasoning', 'thinking', 'domain-specific', 'multilingual', 'multimodal'],
    category: 'reasoning',
    isLatest: true,
    notes: 'Our small multimodal reasoning model released September 2025 (v25.09).'
  },
  {
    id: 'magistral-small-2507',
    name: 'Magistral Small 1.1',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 40000,
    contextLength: 40000,
    pricing: { input: 0.5, output: 1.5 },
    capabilities: ['text', 'reasoning', 'thinking', 'domain-specific', 'multilingual'],
    category: 'reasoning',
    isLatest: false,
    notes: 'Our small reasoning model released July 2025 (v25.07). Deprecated October 31, 2025, retirement November 30, 2025. Use Magistral Small 1.2 instead.'
  },
  {
    id: 'voxtral-small-2507',
    name: 'Voxtral Small',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 32000,
    contextLength: 32000,
    pricing: { input: 0.1, output: 0.1 },
    capabilities: ['audio', 'instruct', 'multimodal'],
    category: 'audio',
    isLatest: true,
    notes: 'Our first model with audio input capabilities for instruct use cases.'
  },
  {
    id: 'voxtral-small-latest',
    name: 'Voxtral Small',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 32000,
    contextLength: 32000,
    pricing: { input: 0.1, output: 0.1 },
    capabilities: ['audio', 'instruct', 'multimodal'],
    category: 'audio',
    isLatest: true,
    notes: 'Our first model with audio input capabilities for instruct use cases.'
  },
  {
    id: 'mistral-small-2506',
    name: 'Mistral Small 3.2',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.1, output: 0.3 },
    capabilities: ['text', 'multimodal', 'multilingual', 'open-source'],
    category: 'multimodal',
    isLatest: true,
    notes: 'An update to our previous small model, released June 2025.'
  },
  {
    id: 'mistral-small-2503',
    name: 'Mistral Small 3.0',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.1, output: 0.3 },
    capabilities: ['text', 'multimodal', 'multilingual', 'open-source'],
    category: 'multimodal',
    isLatest: false,
    notes: 'Mistral Small 3.0 model released March 2025.'
  },
  {
    id: 'ministral-3b',
    name: 'Ministral 3B',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.05, output: 0.15 },
    capabilities: ['text', 'lightweight', 'edge', 'open-source'],
    category: 'text',
    isLatest: true,
    notes: 'World\'s best edge model. 3B parameter model optimized for edge devices.'
  },
  {
    id: 'ministral-8b',
    name: 'Ministral 8B',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.10, output: 0.30 },
    capabilities: ['text', 'edge', 'open-source', 'high-performance'],
    category: 'text',
    isLatest: true,
    notes: 'Powerful edge model with extremely high performance/price ratio. 8B parameter model.'
  },
  {
    id: 'devstral-small-2507',
    name: 'Devstral Small 1.1',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.1, output: 0.3 },
    capabilities: ['code', 'agents', 'open-source', 'codebase-exploration', 'multi-file-editing'],
    category: 'code',
    isLatest: true,
    notes: 'An update to our open source model that excels at using tools to explore codebases, editing multiple files and power software engineering agents.'
  },
  {
    id: 'devstral-small-latest',
    name: 'Devstral Small 1.1',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.1, output: 0.3 },
    capabilities: ['code', 'agents', 'open-source', 'codebase-exploration', 'multi-file-editing'],
    category: 'code',
    isLatest: true,
    notes: 'An update to our open source model that excels at using tools to explore codebases, editing multiple files and power software engineering agents.'
  },
  {
    id: 'mistral-small-2503',
    name: 'Mistral Small 3.1',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.1, output: 0.3 },
    capabilities: ['text', 'multimodal', 'multilingual', 'open-source', 'image-understanding'],
    category: 'multimodal',
    isLatest: false,
    notes: 'A new leader in the small models category with image understanding capabilities, released March 2025.'
  },
  {
    id: 'mistral-small-2501',
    name: 'Mistral Small 3',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 32000,
    contextLength: 32000,
    pricing: { input: 0.1, output: 0.3 },
    capabilities: ['text', 'multimodal', 'multilingual', 'open-source'],
    category: 'multimodal',
    isLatest: false,
    notes: 'A new leader in the small models category, released January 2025.'
  },
  {
    id: 'devstral-small-2505',
    name: 'Devstral Small 1',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.1, output: 0.3 },
    capabilities: ['code', 'agents', 'open-source', '24b-parameter'],
    category: 'code',
    isLatest: false,
    notes: 'A 24B text model, open source model that excels at using tools to explore codebases, editing multiple files and power software engineering agents.'
  },
  {
    id: 'pixtral-12b-2409',
    name: 'Pixtral 12B',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.15, output: 0.15 },
    capabilities: ['vision', 'multimodal', 'small', 'image-understanding'],
    category: 'multimodal',
    isLatest: true,
    notes: 'A 12B model with image understanding capabilities in addition to text.'
  },
  {
    id: 'pixtral-12b',
    name: 'Pixtral 12B',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.15, output: 0.15 },
    capabilities: ['vision', 'multimodal', 'small', 'image-understanding'],
    category: 'multimodal',
    isLatest: true,
    notes: 'A 12B model with image understanding capabilities in addition to text.'
  },
  {
    id: 'open-mistral-nemo-2407',
    name: 'Mistral NeMo 12B',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.15, output: 0.15 },
    capabilities: ['text', 'multilingual', 'open-source', 'best-multilingual'],
    category: 'text',
    isLatest: true,
    notes: 'Our best multilingual open source model released July 2024.'
  },
  {
    id: 'open-mistral-nemo',
    name: 'Mistral NeMo 12B',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.15, output: 0.15 },
    capabilities: ['text', 'multilingual', 'open-source', 'best-multilingual'],
    category: 'text',
    isLatest: true,
    notes: 'Our best multilingual open source model released July 2024.'
  },
  {
    id: 'mistral-nemo',
    name: 'Mistral NeMo',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.15, output: 0.15 },
    capabilities: ['text', 'code', 'specialized'],
    category: 'code',
    isLatest: true,
    notes: 'State-of-the-art Mistral model trained specifically for code tasks.'
  },
  {
    id: 'open-mistral-7b',
    name: 'Mistral 7B',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 32000,
    contextLength: 32000,
    pricing: { input: 0.25, output: 0.25 },
    capabilities: ['text', 'open-source', 'fast'],
    category: 'text',
    isLatest: false,
    notes: 'A 7B transformer model, fast-deployed and easily customisable.'
  },
  {
    id: 'open-mixtral-8x7b',
    name: 'Mixtral 8x7B',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 32000,
    contextLength: 32000,
    pricing: { input: 0.7, output: 0.7 },
    capabilities: ['text', 'mixture-of-experts', 'open-source'],
    category: 'text',
    isLatest: false,
    notes: 'A 7B sparse Mixture-of-Experts (SMoE). Uses 12.9B active parameters out of 45B total.'
  },
  {
    id: 'open-mixtral-8x22b',
    name: 'Mixtral 8x22B',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 65000,
    contextLength: 65000,
    pricing: { input: 2.0, output: 6.0 },
    capabilities: ['text', 'mixture-of-experts', 'open-source', 'high-performance'],
    category: 'text',
    isLatest: false,
    notes: 'Most performant open model. A 22B sparse Mixture-of-Experts (SMoE). Uses only 39B active parameters out of 141B.'
  },
  // === Grok AI Models ===
  // === Grok 4 Fast Series (Latest) ===
  {
    id: 'grok-4-fast-reasoning',
    name: 'Grok 4 Fast Reasoning',
    provider: 'xAI',
    available: true,
    maxTokens: 2000000,
    contextLength: 2000000,
    pricing: { input: 0.20, output: 0.50 },
    capabilities: ['text', 'reasoning', 'function-calling', 'structured-outputs'],
    category: 'text',
    isLatest: true,
    notes: 'Latest cost-efficient reasoning model with 2M context window. Lightning fast, low cost. 4M TPM, 480 RPM rate limits'
  },
  {
    id: 'grok-4-fast-non-reasoning',
    name: 'Grok 4 Fast Non-Reasoning',
    provider: 'xAI',
    available: true,
    maxTokens: 2000000,
    contextLength: 2000000,
    pricing: { input: 0.20, output: 0.50 },
    capabilities: ['text', 'function-calling', 'structured-outputs'],
    category: 'text',
    isLatest: true,
    notes: 'Latest cost-efficient non-reasoning model with 2M context window. Lightning fast, low cost. 4M TPM, 480 RPM rate limits'
  },
  {
    id: 'grok-code-fast-1',
    name: 'Grok Code Fast 1',
    provider: 'xAI',
    available: true,
    maxTokens: 256000,
    contextLength: 256000,
    pricing: { input: 0.20, output: 1.50 },
    capabilities: ['code', 'programming', 'function-calling', 'structured-outputs'],
    category: 'code',
    isLatest: true,
    notes: 'Cost-efficient coding model optimized for code generation and programming tasks. 2M TPM, 480 RPM rate limits'
  },
  // === Grok 4 Series ===
  {
    id: 'grok-4-0709',
    name: 'Grok 4',
    provider: 'xAI',
    available: true,
    maxTokens: 256000,
    contextLength: 256000,
    pricing: { input: 3.0, output: 15.0 },
    capabilities: ['text', 'reasoning', 'function-calling', 'structured-outputs'],
    category: 'text',
    isLatest: true,
    notes: 'Latest Grok 4 reasoning model. Note: Grok 4 is always a reasoning model with no non-reasoning mode. 2M TPM, 480 RPM rate limits. Knowledge cutoff: November 2024'
  },
  {
    id: 'grok-4',
    name: 'Grok 4 (Alias)',
    provider: 'xAI',
    available: true,
    maxTokens: 256000,
    contextLength: 256000,
    pricing: { input: 3.0, output: 15.0 },
    capabilities: ['text', 'reasoning', 'function-calling', 'structured-outputs'],
    category: 'text',
    isLatest: true,
    notes: 'Alias for latest stable Grok 4 version. Points to grok-4-0709. 2M TPM, 480 RPM rate limits'
  },
  {
    id: 'grok-4-latest',
    name: 'Grok 4 Latest',
    provider: 'xAI',
    available: true,
    maxTokens: 256000,
    contextLength: 256000,
    pricing: { input: 3.0, output: 15.0 },
    capabilities: ['text', 'reasoning', 'function-calling', 'structured-outputs'],
    category: 'text',
    isLatest: true,
    notes: 'Alias for latest Grok 4 version (may include preview features). Auto-updates with new releases. 2M TPM, 480 RPM rate limits'
  },
  // === Grok 3 Series ===
  {
    id: 'grok-3',
    name: 'Grok 3',
    provider: 'xAI',
    available: true,
    maxTokens: 131072,
    contextLength: 131072,
    pricing: { input: 3.0, output: 15.0 },
    capabilities: ['text', 'vision', 'function-calling', 'structured-outputs'],
    category: 'multimodal',
    isLatest: false,
    notes: 'Standard Grok 3 model. 600 RPM rate limits. Knowledge cutoff: November 2024'
  },
  {
    id: 'grok-3-mini',
    name: 'Grok 3 Mini',
    provider: 'xAI',
    available: true,
    maxTokens: 131072,
    contextLength: 131072,
    pricing: { input: 0.3, output: 0.5 },
    capabilities: ['text', 'vision', 'function-calling', 'structured-outputs'],
    category: 'multimodal',
    isLatest: false,
    notes: 'Cost-effective Grok 3 Mini model. 480 RPM rate limits. Knowledge cutoff: November 2024'
  },
  // === Grok 2 Vision Series ===
  {
    id: 'grok-2-vision-1212',
    name: 'Grok 2 Vision',
    provider: 'xAI',
    available: true,
    maxTokens: 32768,
    contextLength: 32768,
    pricing: { input: 2.0, output: 10.0 },
    capabilities: ['text', 'vision', 'image-understanding'],
    category: 'multimodal',
    isLatest: false,
    notes: 'Grok 2 Vision model for image understanding. 600 RPM rate limits (us-east-1) or 50 RPS (eu-west-1)'
  },
  {
    id: 'grok-2-vision-1212-us-east-1',
    name: 'Grok 2 Vision (US East)',
    provider: 'xAI',
    available: true,
    maxTokens: 32768,
    contextLength: 32768,
    pricing: { input: 2.0, output: 10.0 },
    capabilities: ['text', 'vision', 'image-understanding'],
    category: 'multimodal',
    isLatest: false,
    notes: 'Grok 2 Vision model for us-east-1 region. 600 RPM rate limits'
  },
  {
    id: 'grok-2-vision-1212-eu-west-1',
    name: 'Grok 2 Vision (EU West)',
    provider: 'xAI',
    available: true,
    maxTokens: 32768,
    contextLength: 32768,
    pricing: { input: 2.0, output: 10.0 },
    capabilities: ['text', 'vision', 'image-understanding'],
    category: 'multimodal',
    isLatest: false,
    notes: 'Grok 2 Vision model for eu-west-1 region. 50 RPS rate limits'
  },
  // === Grok 2 Image Generation ===
  {
    id: 'grok-2-image-1212',
    name: 'Grok 2 Image',
    provider: 'xAI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.07, output: 0.07 },
    capabilities: ['image-generation'],
    category: 'image',
    isLatest: true,
    notes: 'Grok 2 image generation model. $0.07 per image output, 300 RPM rate limits'
  },
  {
    id: 'grok-2-image',
    name: 'Grok 2 Image (Alias)',
    provider: 'xAI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.07, output: 0.07 },
    capabilities: ['image-generation'],
    category: 'image',
    isLatest: true,
    notes: 'Alias for latest stable Grok 2 Image version. Points to grok-2-image-1212. $0.07 per image, 300 RPM rate limits'
  },
  {
    id: 'grok-2-image-latest',
    name: 'Grok 2 Image Latest',
    provider: 'xAI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.07, output: 0.07 },
    capabilities: ['image-generation'],
    category: 'image',
    isLatest: true,
    notes: 'Alias for latest Grok 2 Image version. Auto-updates with new releases. $0.07 per image, 300 RPM rate limits'
  },
  // === Meta Llama Models ===
  // === Llama 4 Series (Latest) ===
  {
    id: 'llama-4-scout',
    name: 'Llama 4 Scout',
    provider: 'Meta',
    available: true,
    maxTokens: 10000000,
    contextLength: 10000000,
    pricing: { input: 0.19, output: 0.49 },
    capabilities: ['text', 'vision', 'multimodal', 'long-context', 'multilingual', 'image-grounding'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Class-leading natively multimodal model with superior text and visual intelligence. 17B active params x 16 experts, 109B total params. Includes Llama Guard 4 12B, Llama Prompt Guard 2 22M and 86M. Licensed under Llama 4 Community License Agreement'
  },
  {
    id: 'llama-4-maverick',
    name: 'Llama 4 Maverick',
    provider: 'Meta',
    available: true,
    maxTokens: 10000000,
    contextLength: 10000000,
    pricing: { input: 0.19, output: 0.49 },
    capabilities: ['text', 'vision', 'multimodal', 'long-context', 'multilingual', 'image-grounding', 'fast-responses'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Industry-leading natively multimodal model with groundbreaking intelligence and fast responses at a low cost. 17B active params x 128 experts, 400B total params. Includes Llama Guard 4 12B, Llama Prompt Guard 2 22M and 86M. Licensed under Llama 4 Community License Agreement'
  },
  {
    id: 'llama-4-behemoth-preview',
    name: 'Llama 4 Behemoth Preview',
    provider: 'Meta',
    available: true,
    maxTokens: 10000000,
    contextLength: 10000000,
    pricing: { input: 0.19, output: 0.49 },
    capabilities: ['text', 'vision', 'multimodal', 'long-context', 'multilingual', 'image-grounding', 'teacher-model'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Early preview of the Llama 4 teacher model used to distill Llama 4 Scout and Llama 4 Maverick. Still in training phase. Licensed under Llama 4 Community License Agreement'
  },
  // === Llama 3.3 Series ===
  {
    id: 'llama-3.3-70b',
    name: 'Llama 3.3 70B',
    provider: 'Meta',
    available: true,
    maxTokens: 131072,
    contextLength: 131072,
    pricing: { input: 0.59, output: 0.79 },
    capabilities: ['text', 'multilingual', 'open-source'],
    category: 'text',
    isLatest: true,
    notes: 'Multilingual open source large language model. Experience 405B performance and quality at a fraction of the cost. Licensed under Llama 3.3 Community License Agreement'
  },
  // === Llama 3.2 Series ===
  {
    id: 'llama-3.2-11b',
    name: 'Llama 3.2 11B',
    provider: 'Meta',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.16, output: 0.16 },
    capabilities: ['text', 'vision', 'multimodal', 'open-source'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Open multimodal model that is flexible and can reason on high resolution images and output text. Includes Llama Guard 3 11B Vision. Licensed under Llama 3.2 Community License Agreement'
  },
  {
    id: 'llama-3.2-90b',
    name: 'Llama 3.2 90B',
    provider: 'Meta',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.72, output: 0.72 },
    capabilities: ['text', 'vision', 'multimodal', 'open-source'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Open multimodal model that is flexible and can reason on high resolution images and output text. Includes Llama Guard 3 11B Vision. Licensed under Llama 3.2 Community License Agreement'
  },
  {
    id: 'llama-3.2-3b',
    name: 'Llama 3.2 3B',
    provider: 'Meta',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.05, output: 0.10 },
    capabilities: ['text', 'lightweight', 'mobile', 'edge', 'open-source'],
    category: 'text',
    isLatest: true,
    notes: 'Lightweight and most cost-efficient model you can run anywhere on mobile and on edge devices. Includes Llama Guard 3 1B. Quantized models available. Licensed under Llama 3.2 Community License Agreement'
  },
  {
    id: 'llama-3.2-1b',
    name: 'Llama 3.2 1B',
    provider: 'Meta',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.05, output: 0.10 },
    capabilities: ['text', 'lightweight', 'mobile', 'edge', 'open-source'],
    category: 'text',
    isLatest: true,
    notes: 'Lightweight and most cost-efficient model you can run anywhere on mobile and on edge devices. Includes Llama Guard 3 1B. Quantized models available. Licensed under Llama 3.2 Community License Agreement'
  },
  // === Llama 3.1 Series ===
  {
    id: 'llama-3.1-405b',
    name: 'Llama 3.1 405B',
    provider: 'Meta',
    available: true,
    maxTokens: 131072,
    contextLength: 131072,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['text', 'multilingual', 'open-source'],
    category: 'text',
    isLatest: false,
    notes: 'Multilingual open source large language model. Includes Llama Guard 3 8B and Llama Prompt Guard 2. Licensed under Llama 3.1 Community License Agreement'
  },
  {
    id: 'llama-3.1-8b',
    name: 'Llama 3.1 8B',
    provider: 'Meta',
    available: true,
    maxTokens: 131072,
    contextLength: 131072,
    pricing: { input: 0.05, output: 0.10 },
    capabilities: ['text', 'multilingual', 'open-source'],
    category: 'text',
    isLatest: false,
    notes: 'Multilingual open source large language model. Includes Llama Guard 3 8B and Llama Prompt Guard 2. Licensed under Llama 3.1 Community License Agreement'
  },
  // === Llama 3 Series (Legacy) ===
  {
    id: 'llama-3-70b',
    name: 'Llama 3 70B',
    provider: 'Meta',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.59, output: 0.79 },
    capabilities: ['text', 'open-source'],
    category: 'text',
    isLatest: false,
    notes: 'Legacy Llama 3 70B model. Licensed under Llama 3 Community License Agreement'
  },
  {
    id: 'llama-3-8b',
    name: 'Llama 3 8B',
    provider: 'Meta',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.05, output: 0.10 },
    capabilities: ['text', 'open-source'],
    category: 'text',
    isLatest: false,
    notes: 'Legacy Llama 3 8B model. Licensed under Llama 3 Community License Agreement'
  }
];

export const getModelsByProvider = (provider?: string): ModelInfo[] => {
  if (!provider) {
    return AVAILABLE_MODELS;
  }
  return AVAILABLE_MODELS.filter(model => 
    model.provider.toLowerCase().includes(provider.toLowerCase())
  );
};

export const getLatestModels = (): ModelInfo[] => {
  return AVAILABLE_MODELS.filter(model => model.isLatest);
};

export const getModelsByCategory = (category?: string): ModelInfo[] => {
  if (!category) {
    return AVAILABLE_MODELS;
  }
  return AVAILABLE_MODELS.filter(model => 
    model.category.toLowerCase() === category.toLowerCase()
  );
};

export const searchModels = (query: string): ModelInfo[] => {
  const lowerQuery = query.toLowerCase();
  return AVAILABLE_MODELS.filter(model => 
    model.name.toLowerCase().includes(lowerQuery) ||
    model.id.toLowerCase().includes(lowerQuery) ||
    model.provider.toLowerCase().includes(lowerQuery) ||
    model.capabilities.some(cap => cap.toLowerCase().includes(lowerQuery))
  );
}; 