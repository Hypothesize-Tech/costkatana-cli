export interface ModelInfo {
  id: string;
  name: string;
  provider: string;
  available: boolean;
  maxTokens: number;
  contextLength: number;
  pricing: {
    input: number;
    output: number;
  };
  capabilities: string[];
  category: string;
  isLatest: boolean;
  notes?: string;
}

export const AVAILABLE_MODELS: ModelInfo[] = [
  // === OpenAI Models ===
  // === GPT-5 Models (Latest) ===
  {
    id: 'gpt-5',
    name: 'GPT-5',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 1.25, output: 10.0 },
    capabilities: ['text', 'reasoning', 'analysis', 'advanced-intelligence'],
    category: 'text',
    isLatest: true,
    notes: 'Latest GPT-5 model with advanced intelligence and reasoning capabilities'
  },
  {
    id: 'gpt-5-mini',
    name: 'GPT-5 Mini',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.25, output: 2.0 },
    capabilities: ['text', 'reasoning', 'analysis', 'efficient'],
    category: 'text',
    isLatest: true,
    notes: 'Efficient GPT-5 variant with balanced performance and cost'
  },
  {
    id: 'gpt-5-nano',
    name: 'GPT-5 Nano',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.05, output: 0.4 },
    capabilities: ['text', 'fast', 'cost-effective'],
    category: 'text',
    isLatest: true,
    notes: 'Fastest and most cost-effective GPT-5 variant'
  },
  {
    id: 'gpt-5-chat-latest',
    name: 'GPT-5 Chat Latest',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 1.25, output: 10.0 },
    capabilities: ['text', 'chat', 'reasoning', 'analysis'],
    category: 'text',
    isLatest: true,
    notes: 'Latest GPT-5 chat model with advanced conversational capabilities'
  },

  // === GPT-4o Models ===
  {
    id: 'gpt-4o-mini-2024-07-18',
    name: 'GPT-4o Mini',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.15, output: 0.6 },
    capabilities: ['text', 'vision', 'multimodal'],
    category: 'text',
    isLatest: true,
    notes: 'Latest GPT-4o Mini model with vision capabilities'
  },
  {
    id: 'gpt-4o',
    name: 'GPT-4o',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 2.5, output: 10.0 },
    capabilities: ['text', 'vision', 'multimodal'],
    category: 'text',
    isLatest: true,
    notes: 'Latest GPT-4o model with enhanced capabilities'
  },
  {
    id: 'gpt-4o-mini',
    name: 'GPT-4o Mini',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.15, output: 0.6 },
    capabilities: ['text', 'vision', 'multimodal'],
    category: 'text',
    isLatest: true,
    notes: 'GPT-4o Mini model with vision capabilities'
  },
  {
    id: 'gpt-4-turbo',
    name: 'GPT-4 Turbo',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 10.0, output: 30.0 },
    capabilities: ['text', 'vision', 'multimodal'],
    category: 'text',
    isLatest: false,
    notes: 'GPT-4 Turbo with vision capabilities'
  },
  {
    id: 'gpt-4',
    name: 'GPT-4',
    provider: 'OpenAI',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 30.0, output: 60.0 },
    capabilities: ['text'],
    category: 'text',
    isLatest: false,
    notes: 'GPT-4 base model'
  },
  {
    id: 'gpt-3.5-turbo',
    name: 'GPT-3.5 Turbo',
    provider: 'OpenAI',
    available: true,
    maxTokens: 16385,
    contextLength: 16385,
    pricing: { input: 0.5, output: 1.5 },
    capabilities: ['text'],
    category: 'text',
    isLatest: false,
    notes: 'GPT-3.5 Turbo model'
  },
  {
    id: 'gpt-4.1-2025-04-14',
    name: 'GPT-4.1',
    provider: 'OpenAI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 2.0, output: 8.0 },
    capabilities: ['text', 'analysis', 'reasoning'],
    category: 'text',
    isLatest: true,
    notes: 'Latest GPT-4.1 model with enhanced capabilities'
  },

  // === Anthropic Models ===
  {
    id: 'claude-opus-4-1-20250805',
    name: 'Claude Opus 4.1',
    provider: 'Anthropic',
    available: true,
    maxTokens: 32000,
    contextLength: 200000,
    pricing: { input: 15.0, output: 75.0 },
    capabilities: ['text', 'vision', 'multimodal', 'reasoning', 'extended-thinking', 'multilingual'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Most capable and intelligent Claude model yet - superior reasoning and advanced coding (Mar 2025 cutoff)'
  },
  {
    id: 'claude-opus-4-20250514',
    name: 'Claude Opus 4',
    provider: 'Anthropic',
    available: true,
    maxTokens: 32000,
    contextLength: 200000,
    pricing: { input: 15.0, output: 75.0 },
    capabilities: ['text', 'vision', 'multimodal', 'reasoning', 'extended-thinking', 'multilingual'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Previous flagship model with very high intelligence and capability (Mar 2025 cutoff)'
  },
  {
    id: 'claude-sonnet-4-20250514',
    name: 'Claude Sonnet 4',
    provider: 'Anthropic',
    available: true,
    maxTokens: 64000,
    contextLength: 200000,
    pricing: { input: 3.0, output: 15.0 },
    capabilities: ['text', 'vision', 'multimodal', 'reasoning', 'extended-thinking', 'multilingual'],
    category: 'multimodal',
    isLatest: true,
    notes: 'High-performance model with exceptional reasoning (Mar 2025 cutoff, 1M context beta available)'
  },
  {
    id: 'claude-3-7-sonnet-20250219',
    name: 'Claude Sonnet 3.7',
    provider: 'Anthropic',
    available: true,
    maxTokens: 64000,
    contextLength: 200000,
    pricing: { input: 3.0, output: 15.0 },
    capabilities: ['text', 'vision', 'multimodal', 'reasoning', 'extended-thinking', 'multilingual'],
    category: 'multimodal',
    isLatest: true,
    notes: 'High-performance model with early extended thinking (Oct 2024 cutoff, 64k output)'
  },
  {
    id: 'claude-3-5-sonnet-20241022',
    name: 'Claude Sonnet 3.5 v2',
    provider: 'Anthropic',
    available: true,
    maxTokens: 8192,
    contextLength: 200000,
    pricing: { input: 3.0, output: 15.0 },
    capabilities: ['text', 'vision', 'multimodal', 'reasoning', 'multilingual'],
    category: 'multimodal',
    isLatest: false,
    notes: 'Upgraded Claude 3.5 Sonnet (Apr 2024 cutoff, 8k output)'
  },
  {
    id: 'claude-3-5-haiku-20241022',
    name: 'Claude Haiku 3.5',
    provider: 'Anthropic',
    available: true,
    maxTokens: 8192,
    contextLength: 200000,
    pricing: { input: 0.8, output: 4.0 },
    capabilities: ['text', 'vision', 'multimodal', 'multilingual'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Fastest Claude model (July 2024 cutoff, 8k output)'
  },

  // === Google AI Models ===
  // === Gemini 2.5 Models (Latest) ===
  {
    id: 'gemini-2.5-pro',
    name: 'Gemini 2.5 Pro',
    provider: 'Google AI',
    available: true,
    maxTokens: 2000000,
    contextLength: 2000000,
    pricing: { input: 1.25, output: 10.0 },
    capabilities: ['text', 'multimodal', 'reasoning', 'coding', 'complex-problems'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Our most advanced reasoning Gemini model, made to solve complex problems. Best for multimodal understanding, coding (web development), and complex prompts'
  },
  {
    id: 'gemini-2.5-flash',
    name: 'Gemini 2.5 Flash',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 0.3, output: 2.5 },
    capabilities: ['text', 'image', 'video', 'multimodal', 'reasoning', 'thinking', 'live-api'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Our best model in terms of price-performance, offering well-rounded capabilities. Support for Live API included for some endpoints. See the model\'s thinking process as part of the response'
  },
  {
    id: 'gemini-2.5-flash-lite-preview',
    name: 'Gemini 2.5 Flash-Lite Preview',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 0.1, output: 0.4 },
    capabilities: ['text', 'image', 'video', 'multimodal', 'reasoning', 'thinking', 'high-throughput'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Our most cost effective model that supports high throughput tasks. The fastest model in the 2.5 line. Features 1M token context window and multimodal input. Outperforms 2.0 Flash on most evaluation benchmarks'
  },
  {
    id: 'gemini-2.5-flash-audio',
    name: 'Gemini 2.5 Flash Audio',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 1.0, output: 2.5 },
    capabilities: ['audio', 'multimodal', 'audio-input'],
    category: 'audio',
    isLatest: true,
    notes: 'Gemini 2.5 Flash with audio input capabilities'
  },
  {
    id: 'gemini-2.5-flash-lite-audio-preview',
    name: 'Gemini 2.5 Flash-Lite Audio Preview',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 0.5, output: 0.4 },
    capabilities: ['audio', 'multimodal', 'audio-input', 'high-throughput'],
    category: 'audio',
    isLatest: true,
    notes: 'Gemini 2.5 Flash-Lite with audio input capabilities'
  },
  {
    id: 'gemini-2.5-flash-native-audio',
    name: 'Gemini 2.5 Flash Native Audio',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 0.5, output: 2.0 },
    capabilities: ['audio', 'multimodal', 'native-audio'],
    category: 'audio',
    isLatest: true,
    notes: 'Native audio model optimized for higher quality audio outputs'
  },
  {
    id: 'gemini-2.5-flash-native-audio-output',
    name: 'Gemini 2.5 Flash Native Audio Output',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 3.0, output: 12.0 },
    capabilities: ['audio', 'multimodal', 'native-audio', 'audio-output'],
    category: 'audio',
    isLatest: true,
    notes: 'Native audio model with audio output capabilities'
  },
  {
    id: 'gemini-2.5-flash-preview-tts',
    name: 'Gemini 2.5 Flash Preview TTS',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 0.5, output: 10.0 },
    capabilities: ['text-to-speech', 'audio', 'tts'],
    category: 'audio',
    isLatest: true,
    notes: '2.5 Flash TTS model optimized for price-performant, low-latency speech generation'
  },
  {
    id: 'gemini-2.5-pro-preview-tts',
    name: 'Gemini 2.5 Pro Preview TTS',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 1.0, output: 20.0 },
    capabilities: ['text-to-speech', 'audio', 'tts'],
    category: 'audio',
    isLatest: true,
    notes: '2.5 Pro TTS model optimized for powerful, low-latency speech generation'
  },

  // === Gemini 2.0 Models ===
  {
    id: 'gemini-2.0-flash',
    name: 'Gemini 2.0 Flash',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 0.1, output: 0.4 },
    capabilities: ['text', 'image', 'video', 'multimodal', 'agents', 'next-generation'],
    category: 'multimodal',
    isLatest: false,
    notes: 'Our newest multimodal model, with next generation features and improved capabilities. Most balanced multimodal model built for the era of Agents'
  },
  {
    id: 'gemini-2.0-flash-lite',
    name: 'Gemini 2.0 Flash-Lite',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 0.075, output: 0.3 },
    capabilities: ['text', 'multimodal', 'cost-efficient', 'low-latency'],
    category: 'multimodal',
    isLatest: false,
    notes: 'A Gemini 2.0 Flash model optimized for cost efficiency and low latency. Smallest and most cost effective model, built for at scale usage'
  },
  {
    id: 'gemini-2.0-flash-audio',
    name: 'Gemini 2.0 Flash Audio',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 0.7, output: 0.4 },
    capabilities: ['audio', 'multimodal', 'audio-input'],
    category: 'audio',
    isLatest: false,
    notes: 'Gemini 2.0 Flash with audio input capabilities'
  },

  // === Gemini 1.5 Models ===
  {
    id: 'gemini-1.5-flash',
    name: 'Gemini 1.5 Flash',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 0.075, output: 0.3 },
    capabilities: ['text', 'image', 'video', 'multimodal'],
    category: 'multimodal',
    isLatest: false,
    notes: 'Fastest multimodal model for diverse, repetitive tasks'
  },
  {
    id: 'gemini-1.5-flash-large-context',
    name: 'Gemini 1.5 Flash Large Context',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 0.15, output: 0.6 },
    capabilities: ['text', 'image', 'video', 'multimodal', 'large-context'],
    category: 'multimodal',
    isLatest: false,
    notes: 'Gemini 1.5 Flash with large context pricing (>128k tokens)'
  },
  {
    id: 'gemini-1.5-flash-8b',
    name: 'Gemini 1.5 Flash-8B',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 0.0375, output: 0.15 },
    capabilities: ['text', 'image', 'video', 'multimodal', 'efficient'],
    category: 'multimodal',
    isLatest: false,
    notes: 'Smallest model for lower intelligence use cases'
  },
  {
    id: 'gemini-1.5-flash-8b-large-context',
    name: 'Gemini 1.5 Flash-8B Large Context',
    provider: 'Google AI',
    available: true,
    maxTokens: 1000000,
    contextLength: 1000000,
    pricing: { input: 0.075, output: 0.3 },
    capabilities: ['text', 'image', 'video', 'multimodal', 'efficient', 'large-context'],
    category: 'multimodal',
    isLatest: false,
    notes: 'Gemini 1.5 Flash-8B with large context pricing (>128k tokens)'
  },
  {
    id: 'gemini-1.5-pro',
    name: 'Gemini 1.5 Pro',
    provider: 'Google AI',
    available: true,
    maxTokens: 2000000,
    contextLength: 2000000,
    pricing: { input: 1.25, output: 5.0 },
    capabilities: ['text', 'code', 'reasoning', 'multimodal'],
    category: 'text',
    isLatest: false,
    notes: 'Highest intelligence Gemini 1.5 series model with 2M context'
  },
  {
    id: 'gemini-1.5-pro-large-context',
    name: 'Gemini 1.5 Pro Large Context',
    provider: 'Google AI',
    available: true,
    maxTokens: 2000000,
    contextLength: 2000000,
    pricing: { input: 2.5, output: 10.0 },
    capabilities: ['text', 'code', 'reasoning', 'multimodal', 'large-context'],
    category: 'text',
    isLatest: false,
    notes: 'Gemini 1.5 Pro with large context pricing (>128k tokens)'
  },

  // === Gemma Models (Open Source) ===
  {
    id: 'gemma-3n',
    name: 'Gemma 3n',
    provider: 'Google AI',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['text', 'open-source', 'multimodal', '140-languages', 'mobile-optimized'],
    category: 'text',
    isLatest: true,
    notes: 'The latest open models, designed for efficient execution on low-resource devices, capable of multimodal input (text, image, video, audio), and trained with data in over 140 spoken languages'
  },
  {
    id: 'gemma-3',
    name: 'Gemma 3',
    provider: 'Google AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['text', 'open-source', 'multimodal', '140-languages', 'wide-variety-tasks'],
    category: 'text',
    isLatest: true,
    notes: 'The third generation of our open models, featuring the ability to solve a wide variety of tasks with text and image input, support for over 140 languages, and long 128K context window'
  },
  {
    id: 'gemma-2',
    name: 'Gemma 2',
    provider: 'Google AI',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['text', 'open-source', 'text-generation', 'summarization', 'extraction'],
    category: 'text',
    isLatest: false,
    notes: 'The second generation of our open models featuring text generation, summarization, and extraction'
  },
  {
    id: 'gemma',
    name: 'Gemma',
    provider: 'Google AI',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['text', 'open-source', 'text-generation', 'summarization', 'extraction', 'lightweight'],
    category: 'text',
    isLatest: false,
    notes: 'A small-sized, lightweight open model supporting text generation, summarization, and extraction'
  },

  // === Specialized Gemma Models ===
  {
    id: 'shieldgemma-2',
    name: 'ShieldGemma 2',
    provider: 'Google AI',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['text', 'open-source', 'safety-evaluation', 'instruction-tuned'],
    category: 'safety',
    isLatest: true,
    notes: 'Instruction tuned models for evaluating the safety of text and images against a set of defined safety policies'
  },
  {
    id: 'paligemma',
    name: 'PaliGemma',
    provider: 'Google AI',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['text', 'open-source', 'vision-language', 'siglip', 'gemma'],
    category: 'vision-language',
    isLatest: true,
    notes: 'Our open vision-language model that combines SigLIP and Gemma'
  },
  {
    id: 'codegemma',
    name: 'CodeGemma',
    provider: 'Google AI',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['text', 'open-source', 'coding', 'fill-in-middle', 'code-generation', 'mathematical-reasoning'],
    category: 'coding',
    isLatest: true,
    notes: 'Powerful, lightweight open model that can perform a variety of coding tasks like fill-in-the-middle code completion, code generation, natural language understanding, mathematical reasoning, and instruction following'
  },
  {
    id: 'txgemma',
    name: 'TxGemma',
    provider: 'Google AI',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['text', 'open-source', 'therapeutic', 'predictions', 'classifications', 'efficient-training'],
    category: 'therapeutic',
    isLatest: true,
    notes: 'Generates predictions, classifications or text based on therapeutic related data and can be used to efficiently build AI models for therapeutic-related tasks with less data and less compute'
  },
  {
    id: 'medgemma',
    name: 'MedGemma',
    provider: 'Google AI',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['text', 'open-source', 'medical', 'medical-comprehension', 'variants'],
    category: 'medical',
    isLatest: true,
    notes: 'Collection of Gemma 3 variants that are trained for performance on medical text and image comprehension'
  },
  {
    id: 'medsiglip',
    name: 'MedSigLIP',
    provider: 'Google AI',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['text', 'open-source', 'medical', 'medical-images', 'embedding-space'],
    category: 'medical',
    isLatest: true,
    notes: 'SigLIP variant that is trained to encode medical images and text into a common embedding space'
  },
  {
    id: 't5gemma',
    name: 'T5Gemma',
    provider: 'Google AI',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['text', 'open-source', 'encoder-decoder', 'research', 'lightweight', 'powerful'],
    category: 'research',
    isLatest: true,
    notes: 'A family of lightweight yet powerful encoder-decoder research models from Google'
  },

  // === Embeddings Models ===
  {
    id: 'text-embedding-004',
    name: 'Text Embedding 004',
    provider: 'Google AI',
    available: true,
    maxTokens: 2048,
    contextLength: 2048,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['embedding', 'semantic-search', 'classification', 'clustering'],
    category: 'embedding',
    isLatest: true,
    notes: 'State-of-the-art text embedding model for semantic search, classification, clustering, and similar tasks'
  },
  {
    id: 'multimodal-embeddings',
    name: 'Multimodal Embeddings',
    provider: 'Google AI',
    available: true,
    maxTokens: 2048,
    contextLength: 2048,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['embedding', 'multimodal', 'image-classification', 'image-search'],
    category: 'embedding',
    isLatest: true,
    notes: 'Generates vectors based on images, which can be used for downstream tasks like image classification, image search, and more'
  },

  // === Imagen Models (Image Generation) ===
  {
    id: 'imagen-4-generation',
    name: 'Imagen 4 for Generation',
    provider: 'Google AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.04, output: 0.04 },
    capabilities: ['image-generation', 'text-to-image', 'higher-quality'],
    category: 'image',
    isLatest: true,
    notes: 'Use text prompts to generate novel images with higher quality than our previous image generation models'
  },
  {
    id: 'imagen-4-fast-generation',
    name: 'Imagen 4 for Fast Generation',
    provider: 'Google AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.04, output: 0.04 },
    capabilities: ['image-generation', 'text-to-image', 'higher-quality', 'lower-latency'],
    category: 'image',
    isLatest: true,
    notes: 'Use text prompts to generate novel images with higher quality and lower latency than our previous image generation models'
  },
  {
    id: 'imagen-4-ultra-generation',
    name: 'Imagen 4 for Ultra Generation',
    provider: 'Google AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.06, output: 0.06 },
    capabilities: ['image-generation', 'text-to-image', 'higher-quality', 'better-prompt-adherence'],
    category: 'image',
    isLatest: true,
    notes: 'Use text prompts to generate novel images with higher quality and better prompt adherence than our previous image generation models'
  },
  {
    id: 'imagen-3-generation',
    name: 'Imagen 3 for Generation',
    provider: 'Google AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.03, output: 0.03 },
    capabilities: ['image-generation', 'text-to-image'],
    category: 'image',
    isLatest: false,
    notes: 'Use text prompts to generate novel images'
  },
  {
    id: 'imagen-3-editing-customization',
    name: 'Imagen 3 for Editing and Customization',
    provider: 'Google AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.03, output: 0.03 },
    capabilities: ['image-generation', 'text-to-image', 'image-editing', 'customization', 'mask-editing'],
    category: 'image',
    isLatest: false,
    notes: 'Use text prompts to edit existing input images, or parts of an image with a mask or generate new images based upon the context provided by input reference images'
  },
  {
    id: 'imagen-3-fast-generation',
    name: 'Imagen 3 for Fast Generation',
    provider: 'Google AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.03, output: 0.03 },
    capabilities: ['image-generation', 'text-to-image', 'lower-latency'],
    category: 'image',
    isLatest: false,
    notes: 'Use text prompts to generate novel images with lower latency than our other image generation models'
  },
  {
    id: 'imagen-captioning-vqa',
    name: 'Imagen for Captioning & VQA',
    provider: 'Google AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.03, output: 0.03 },
    capabilities: ['image-generation', 'text-to-image', 'image-editing', 'mask-editing', 'captioning', 'vqa'],
    category: 'image',
    isLatest: false,
    notes: 'Use text prompts to generate novel images, edit existing ones, edit parts of an image with a mask and more'
  },

  // === Veo Models (Video Generation) ===
  {
    id: 'veo-2',
    name: 'Veo 2',
    provider: 'Google AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.35, output: 0.35 },
    capabilities: ['video-generation', 'text-to-video', 'image-to-video', 'higher-quality'],
    category: 'video',
    isLatest: true,
    notes: 'Use text prompts and images to generate novel videos with higher quality than our previous video generation model (priced per second)'
  },
  {
    id: 'veo-3',
    name: 'Veo 3',
    provider: 'Google AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.35, output: 0.35 },
    capabilities: ['video-generation', 'text-to-video', 'image-to-video', 'higher-quality'],
    category: 'video',
    isLatest: true,
    notes: 'Use text prompts and images to generate novel videos with higher quality than our previous video generation model (priced per second)'
  },
  {
    id: 'veo-3-fast',
    name: 'Veo 3 Fast',
    provider: 'Google AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.35, output: 0.35 },
    capabilities: ['video-generation', 'text-to-video', 'image-to-video', 'higher-quality', 'lower-latency'],
    category: 'video',
    isLatest: true,
    notes: 'Use text prompts and images to generate novel videos with higher quality and lower latency than our previous video generation model (priced per second)'
  },

  // === Preview Models ===
  {
    id: 'virtual-try-on',
    name: 'Virtual Try-On',
    provider: 'Google AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['image-generation', 'virtual-try-on', 'clothing'],
    category: 'image',
    isLatest: true,
    notes: 'Generate images of people wearing clothing products (preview model, free tier only)'
  },
  {
    id: 'veo-3-preview',
    name: 'Veo 3 Preview',
    provider: 'Google AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.35, output: 0.35 },
    capabilities: ['video-generation', 'text-to-video', 'image-to-video', 'higher-quality', 'preview'],
    category: 'video',
    isLatest: true,
    notes: 'Use text prompts and images to generate novel videos with higher quality than our previous video generation model (preview model, priced per second)'
  },
  {
    id: 'veo-3-fast-preview',
    name: 'Veo 3 Fast Preview',
    provider: 'Google AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.35, output: 0.35 },
    capabilities: ['video-generation', 'text-to-video', 'image-to-video', 'higher-quality', 'lower-latency', 'preview'],
    category: 'video',
    isLatest: true,
    notes: 'Use text prompts and images to generate novel videos with higher quality and lower latency than our previous video generation model (preview model, priced per second)'
  },

  // === Legacy Models for Backward Compatibility ===
  {
    id: 'gemini-1.0-pro',
    name: 'Gemini 1.0 Pro',
    provider: 'Google AI',
    available: true,
    maxTokens: 32768,
    contextLength: 32768,
    pricing: { input: 1.0, output: 2.0 },
    capabilities: ['text', 'vision', 'multimodal'],
    category: 'text',
    isLatest: false,
    notes: 'Earlier generation Gemini model (legacy)'
  },
  {
    id: 'gemini-1.0-pro-vision',
    name: 'Gemini 1.0 Pro Vision',
    provider: 'Google AI',
    available: true,
    maxTokens: 32768,
    contextLength: 32768,
    pricing: { input: 1.0, output: 2.0 },
    capabilities: ['text', 'vision', 'multimodal'],
    category: 'text',
    isLatest: false,
    notes: 'Earlier generation Gemini model with vision capabilities (legacy)'
  },

  // === AWS Bedrock Models ===
  {
    id: 'ai21.jamba-1-5-large-v1:0',
    name: 'Jamba 1.5 Large (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 256000,
    contextLength: 256000,
    pricing: { input: 2.0, output: 8.0 },
    capabilities: ['text', 'long-context'],
    category: 'text',
    isLatest: true,
    notes: 'AI21 Labs Jamba 1.5 Large via AWS Bedrock'
  },
  {
    id: 'ai21.jamba-1-5-mini-v1:0',
    name: 'Jamba 1.5 Mini (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 256000,
    contextLength: 256000,
    pricing: { input: 0.2, output: 0.4 },
    capabilities: ['text', 'long-context', 'efficient'],
    category: 'text',
    isLatest: true,
    notes: 'AI21 Labs Jamba 1.5 Mini via AWS Bedrock'
  },
  {
    id: 'amazon.nova-micro-v1:0',
    name: 'Amazon Nova Micro (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.035, output: 0.14 },
    capabilities: ['text', 'ultra-fast', 'cost-effective'],
    category: 'text',
    isLatest: true,
    notes: 'Amazon Nova Micro via AWS Bedrock'
  },
  {
    id: 'amazon.nova-lite-v1:0',
    name: 'Amazon Nova Lite (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 300000,
    contextLength: 300000,
    pricing: { input: 0.06, output: 0.24 },
    capabilities: ['text', 'multimodal', 'fast'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Amazon Nova Lite via AWS Bedrock'
  },
  {
    id: 'amazon.nova-pro-v1:0',
    name: 'Amazon Nova Pro (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 300000,
    contextLength: 300000,
    pricing: { input: 0.8, output: 3.2 },
    capabilities: ['text', 'multimodal', 'reasoning'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Amazon Nova Pro via AWS Bedrock'
  },
  {
    id: 'amazon.nova-premier-v1:0',
    name: 'Amazon Nova Premier (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 300000,
    contextLength: 300000,
    pricing: { input: 2.5, output: 12.5 },
    capabilities: ['text', 'multimodal', 'advanced-reasoning'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Amazon Nova Premier via AWS Bedrock'
  },
  {
    id: 'amazon.nova-canvas-v1:0',
    name: 'Amazon Nova Canvas (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 4096,
    contextLength: 4096,
    pricing: { input: 0.04, output: 0.04 },
    capabilities: ['image-generation'],
    category: 'image',
    isLatest: true,
    notes: 'Amazon Nova Canvas via AWS Bedrock - image generation model'
  },
  {
    id: 'amazon.nova-reel-v1:0',
    name: 'Amazon Nova Reel (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 4096,
    contextLength: 4096,
    pricing: { input: 0.08, output: 0.08 },
    capabilities: ['video-generation'],
    category: 'video',
    isLatest: true,
    notes: 'Amazon Nova Reel via AWS Bedrock - video generation model'
  },
  {
    id: 'amazon.nova-sonic-v1:0',
    name: 'Amazon Nova Sonic (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 300000,
    contextLength: 300000,
    pricing: { input: 3.4, output: 13.6 },
    capabilities: ['speech', 'multimodal', 'native-audio'],
    category: 'audio',
    isLatest: true,
    notes: 'Amazon Nova Sonic via AWS Bedrock - speech model'
  },
  {
    id: 'amazon.titan-text-express-v1',
    name: 'Amazon Titan Text Express (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 8000,
    contextLength: 8000,
    pricing: { input: 0.8, output: 1.6 },
    capabilities: ['text'],
    category: 'text',
    isLatest: true,
    notes: 'Amazon Titan Text Express via AWS Bedrock'
  },
  {
    id: 'amazon.titan-text-lite-v1',
    name: 'Amazon Titan Text Lite (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 4000,
    contextLength: 4000,
    pricing: { input: 0.3, output: 0.4 },
    capabilities: ['text'],
    category: 'text',
    isLatest: true,
    notes: 'Amazon Titan Text Lite via AWS Bedrock'
  },
  {
    id: 'amazon.titan-embed-text-v2:0',
    name: 'Amazon Titan Text Embeddings V2 (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.02, output: 0.02 },
    capabilities: ['embedding'],
    category: 'embedding',
    isLatest: true,
    notes: 'Amazon Titan Text Embeddings V2 via AWS Bedrock'
  },
  {
    id: 'anthropic.claude-opus-4-1-20250805-v1:0',
    name: 'Claude Opus 4.1 (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 32000,
    contextLength: 200000,
    pricing: { input: 15.0, output: 75.0 },
    capabilities: ['text', 'vision', 'multimodal', 'reasoning', 'extended-thinking', 'multilingual'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Claude Opus 4.1 via AWS Bedrock - most capable and intelligent Claude model yet'
  },
  {
    id: 'anthropic.claude-opus-4-20250514-v1:0',
    name: 'Claude Opus 4 (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 32000,
    contextLength: 200000,
    pricing: { input: 15.0, output: 75.0 },
    capabilities: ['text', 'vision', 'multimodal', 'reasoning', 'extended-thinking', 'multilingual'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Claude Opus 4 via AWS Bedrock - previous flagship model'
  },
  {
    id: 'anthropic.claude-sonnet-4-20250514-v1:0',
    name: 'Claude Sonnet 4 (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 64000,
    contextLength: 200000,
    pricing: { input: 3.0, output: 15.0 },
    capabilities: ['text', 'vision', 'multimodal', 'reasoning', 'extended-thinking', 'multilingual'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Claude Sonnet 4 via AWS Bedrock - high-performance model with exceptional reasoning'
  },
  {
    id: 'anthropic.claude-3-7-sonnet-20250219-v1:0',
    name: 'Claude Sonnet 3.7 (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 64000,
    contextLength: 200000,
    pricing: { input: 3.0, output: 15.0 },
    capabilities: ['text', 'vision', 'multimodal', 'reasoning', 'extended-thinking', 'multilingual'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Claude Sonnet 3.7 via AWS Bedrock - high-performance model with early extended thinking'
  },
  {
    id: 'anthropic.claude-3-5-sonnet-20241022-v1:0',
    name: 'Claude Sonnet 3.5 v2 (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 8192,
    contextLength: 200000,
    pricing: { input: 3.0, output: 15.0 },
    capabilities: ['text', 'vision', 'multimodal', 'reasoning', 'multilingual'],
    category: 'multimodal',
    isLatest: false,
    notes: 'Claude Sonnet 3.5 v2 via AWS Bedrock - upgraded version'
  },
  {
    id: 'anthropic.claude-3-5-haiku-20241022-v1:0',
    name: 'Claude Haiku 3.5 (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 8192,
    contextLength: 200000,
    pricing: { input: 0.8, output: 4.0 },
    capabilities: ['text', 'vision', 'multimodal', 'multilingual'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Claude Haiku 3.5 via AWS Bedrock - fastest Claude model'
  },
  {
    id: 'meta.llama3-70b-instruct-v1:0',
    name: 'Llama 3 70B Instruct (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.59, output: 0.79 },
    capabilities: ['text', 'instruction-following'],
    category: 'text',
    isLatest: true,
    notes: 'Meta Llama 3 70B Instruct via AWS Bedrock'
  },
  {
    id: 'meta.llama3-8b-instruct-v1:0',
    name: 'Llama 3 8B Instruct (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.05, output: 0.10 },
    capabilities: ['text', 'instruction-following', 'fast'],
    category: 'text',
    isLatest: true,
    notes: 'Meta Llama 3 8B Instruct via AWS Bedrock'
  },
  {
    id: 'meta.llama3-2-11b-instruct-v1:0',
    name: 'Llama 3.2 11B Instruct (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.16, output: 0.16 },
    capabilities: ['text', 'instruction-following', 'vision'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Meta Llama 3.2 11B Instruct via AWS Bedrock'
  },
  {
    id: 'meta.llama3-2-90b-instruct-v1:0',
    name: 'Llama 3.2 90B Instruct (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.72, output: 0.72 },
    capabilities: ['text', 'instruction-following', 'vision'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Meta Llama 3.2 90B Instruct via AWS Bedrock'
  },
  {
    id: 'meta.llama4-scout-17b-instruct-v1:0',
    name: 'Llama 4 Scout 17B Instruct (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.17, output: 0.66 },
    capabilities: ['text', 'instruction-following', 'vision'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Meta Llama 4 Scout 17B Instruct via AWS Bedrock'
  },
  {
    id: 'meta.llama4-maverick-17b-instruct-v1:0',
    name: 'Llama 4 Maverick 17B Instruct (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.24, output: 0.97 },
    capabilities: ['text', 'instruction-following', 'vision'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Meta Llama 4 Maverick 17B Instruct via AWS Bedrock'
  },
  {
    id: 'mistral.mistral-7b-instruct-v0:2',
    name: 'Mistral 7B Instruct (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 32768,
    contextLength: 32768,
    pricing: { input: 0.15, output: 0.45 },
    capabilities: ['text', 'instruction-following', 'fast'],
    category: 'text',
    isLatest: true,
    notes: 'Mistral 7B Instruct via AWS Bedrock'
  },
  {
    id: 'mistral.mixtral-8x7b-instruct-v0:1',
    name: 'Mixtral 8x7B Instruct (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 32768,
    contextLength: 32768,
    pricing: { input: 0.24, output: 0.72 },
    capabilities: ['text', 'instruction-following', 'mixture-of-experts'],
    category: 'text',
    isLatest: true,
    notes: 'Mistral Mixtral 8x7B Instruct via AWS Bedrock'
  },
  {
    id: 'mistral.mistral-large-2402-v1:0',
    name: 'Mistral Large (24.02) (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 32768,
    contextLength: 32768,
    pricing: { input: 6.50, output: 25.00 },
    capabilities: ['text', 'instruction-following'],
    category: 'text',
    isLatest: true,
    notes: 'Mistral Large via AWS Bedrock'
  },
  {
    id: 'mistral.mistral-small-2402-v1:0',
    name: 'Mistral Small (24.02) (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 32768,
    contextLength: 32768,
    pricing: { input: 2.00, output: 6.00 },
    capabilities: ['text', 'instruction-following'],
    category: 'text',
    isLatest: true,
    notes: 'Mistral Small via AWS Bedrock'
  },
  {
    id: 'mistral.pixtral-large-2502-v1:0',
    name: 'Pixtral Large (25.02) (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 2.0, output: 6.0 },
    capabilities: ['vision', 'multimodal', 'reasoning'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Mistral Pixtral Large via AWS Bedrock'
  },
  {
    id: 'cohere.command-r-plus-v1:0',
    name: 'Command R+ (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 2.5, output: 10.0 },
    capabilities: ['text', 'multilingual', 'enterprise'],
    category: 'text',
    isLatest: true,
    notes: 'Cohere Command R+ via AWS Bedrock - updated pricing'
  },
  {
    id: 'cohere.command-r-v1:0',
    name: 'Command R (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.15, output: 0.6 },
    capabilities: ['text', 'multilingual', 'rag', 'tools'],
    category: 'text',
    isLatest: true,
    notes: 'Cohere Command R via AWS Bedrock - updated pricing'
  },
  {
    id: 'cohere.embed-english-v3',
    name: 'Embed English v3 (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 512,
    contextLength: 512,
    pricing: { input: 0.1, output: 0.1 },
    capabilities: ['embedding'],
    category: 'embedding',
    isLatest: true,
    notes: 'Cohere Embed English v3 via AWS Bedrock'
  },
  {
    id: 'cohere.embed-multilingual-v3',
    name: 'Embed Multilingual v3 (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 512,
    contextLength: 512,
    pricing: { input: 0.1, output: 0.1 },
    capabilities: ['embedding', 'multilingual'],
    category: 'embedding',
    isLatest: true,
    notes: 'Cohere Embed Multilingual v3 via AWS Bedrock'
  },
  // Latest Cohere Models
  {
    id: 'command-a-03-2025',
    name: 'Command A',
    provider: 'Cohere',
    available: true,
    maxTokens: 256000,
    contextLength: 256000,
    pricing: { input: 2.5, output: 10.0 },
    capabilities: ['text', 'agentic', 'multilingual', 'human-evaluations'],
    category: 'text',
    isLatest: true,
    notes: 'Most performant model to date, excelling at tool use, agents, RAG, and multilingual use cases'
  },
  {
    id: 'command-r7b-12-2024',
    name: 'Command R7B',
    provider: 'Cohere',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.0375, output: 0.15 },
    capabilities: ['text', 'rag', 'tool-use', 'agents'],
    category: 'text',
    isLatest: true,
    notes: 'Small, fast update delivered in December 2024, excels at RAG, tool use, and complex reasoning'
  },
  {
    id: 'command-a-reasoning-08-2025',
    name: 'Command A Reasoning',
    provider: 'Cohere',
    available: true,
    maxTokens: 256000,
    contextLength: 256000,
    pricing: { input: 2.5, output: 10.0 },
    capabilities: ['text', 'reasoning', 'agentic', 'multilingual'],
    category: 'text',
    isLatest: true,
    notes: 'First reasoning model, able to think before generating output for nuanced problem-solving and agent-based tasks in 23 languages'
  },
  {
    id: 'command-a-vision-07-2025',
    name: 'Command A Vision',
    provider: 'Cohere',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 2.5, output: 10.0 },
    capabilities: ['text', 'vision', 'multimodal', 'enterprise'],
    category: 'multimodal',
    isLatest: true,
    notes: 'First model capable of processing images, excelling in enterprise use cases like charts, graphs, diagrams, table understanding, OCR, and object detection'
  },
  {
    id: 'command-r-plus-04-2024',
    name: 'Command R+',
    provider: 'Cohere',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 2.5, output: 10.0 },
    capabilities: ['text', 'enterprise', 'rag', 'tools', 'multilingual'],
    category: 'text',
    isLatest: true,
    notes: 'Instruction-following conversational model for complex RAG workflows and multi-step tool use'
  },
  {
    id: 'command-r-08-2024',
    name: 'Command R (08-2024)',
    provider: 'Cohere',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.15, output: 0.6 },
    capabilities: ['text', 'rag', 'tools', 'agents'],
    category: 'text',
    isLatest: true,
    notes: 'Update of Command R model delivered in August 2024'
  },
  {
    id: 'command-r-03-2024',
    name: 'Command R (03-2024)',
    provider: 'Cohere',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.15, output: 0.6 },
    capabilities: ['text', 'rag', 'tools', 'agents'],
    category: 'text',
    isLatest: false,
    notes: 'Instruction-following conversational model for complex workflows like code generation, RAG, tool use, and agents'
  },
  {
    id: 'command',
    name: 'Command',
    provider: 'Cohere',
    available: true,
    maxTokens: 4096,
    contextLength: 4096,
    pricing: { input: 0.15, output: 0.6 },
    capabilities: ['text', 'conversational'],
    category: 'text',
    isLatest: false,
    notes: 'Instruction-following conversational model for language tasks with high quality and reliability'
  },
  {
    id: 'command-nightly',
    name: 'Command Nightly',
    provider: 'Cohere',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.15, output: 0.6 },
    capabilities: ['text', 'experimental', 'nightly'],
    category: 'text',
    isLatest: false,
    notes: 'Latest experimental version, not recommended for production use'
  },
  {
    id: 'command-light',
    name: 'Command Light',
    provider: 'Cohere',
    available: true,
    maxTokens: 4096,
    contextLength: 4096,
    pricing: { input: 0.15, output: 0.6 },
    capabilities: ['text', 'lightweight', 'fast'],
    category: 'text',
    isLatest: false,
    notes: 'Smaller, faster version of command, almost as capable but much faster'
  },
  {
    id: 'command-light-nightly',
    name: 'Command Light Nightly',
    provider: 'Cohere',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.15, output: 0.6 },
    capabilities: ['text', 'lightweight', 'experimental', 'nightly'],
    category: 'text',
    isLatest: false,
    notes: 'Latest experimental version of command-light, not recommended for production use'
  },
  {
    id: 'rerank-v3.5',
    name: 'Rerank v3.5',
    provider: 'Cohere',
    available: true,
    maxTokens: 4096,
    contextLength: 4096,
    pricing: { input: 2.0, output: 2.0 },
    capabilities: ['rerank', 'semantic-search', 'retrieval'],
    category: 'rerank',
    isLatest: true,
    notes: 'Provides powerful semantic boost to search quality of any keyword or vector search system, $2.00 per 1K searches'
  },
  {
    id: 'rerank-english-v3.0',
    name: 'Rerank English v3.0',
    provider: 'Cohere',
    available: true,
    maxTokens: 4096,
    contextLength: 4096,
    pricing: { input: 2.0, output: 2.0 },
    capabilities: ['rerank', 'semantic-search', 'english'],
    category: 'rerank',
    isLatest: true,
    notes: 'English language document and semi-structured data reranking model'
  },
  {
    id: 'rerank-multilingual-v3.0',
    name: 'Rerank Multilingual v3.0',
    provider: 'Cohere',
    available: true,
    maxTokens: 4096,
    contextLength: 4096,
    pricing: { input: 2.0, output: 2.0 },
    capabilities: ['rerank', 'semantic-search', 'multilingual'],
    category: 'rerank',
    isLatest: true,
    notes: 'Multilingual document and semi-structured data reranking model'
  },
  {
    id: 'embed-v4.0',
    name: 'Embed v4.0',
    provider: 'Cohere',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.12, output: 0.12 },
    capabilities: ['embedding', 'multimodal', 'semantic-search', 'rag'],
    category: 'embedding',
    isLatest: true,
    notes: 'Leading multimodal embedding model for text and images, acts as intelligent retrieval engine for semantic search and RAG systems'
  },
  {
    id: 'embed-english-v3.0',
    name: 'Embed English v3.0',
    provider: 'Cohere',
    available: true,
    maxTokens: 512,
    contextLength: 512,
    pricing: { input: 0.1, output: 0.1 },
    capabilities: ['embedding', 'english'],
    category: 'embedding',
    isLatest: true,
    notes: 'English-only embedding model for text classification and embeddings'
  },
  {
    id: 'embed-english-light-v3.0',
    name: 'Embed English Light v3.0',
    provider: 'Cohere',
    available: true,
    maxTokens: 512,
    contextLength: 512,
    pricing: { input: 0.1, output: 0.1 },
    capabilities: ['embedding', 'english', 'lightweight'],
    category: 'embedding',
    isLatest: true,
    notes: 'Smaller, faster version of embed-english-v3.0, almost as capable but much faster'
  },
  {
    id: 'embed-multilingual-v3.0',
    name: 'Embed Multilingual v3.0',
    provider: 'Cohere',
    available: true,
    maxTokens: 512,
    contextLength: 512,
    pricing: { input: 0.1, output: 0.1 },
    capabilities: ['embedding', 'multilingual'],
    category: 'embedding',
    isLatest: true,
    notes: 'Multilingual embedding model for classification and embeddings in multiple languages'
  },
  {
    id: 'embed-multilingual-light-v3.0',
    name: 'Embed Multilingual Light v3.0',
    provider: 'Cohere',
    available: true,
    maxTokens: 512,
    contextLength: 512,
    pricing: { input: 0.1, output: 0.1 },
    capabilities: ['embedding', 'multilingual', 'lightweight'],
    category: 'embedding',
    isLatest: true,
    notes: 'Smaller, faster version of embed-multilingual-v3.0, almost as capable but much faster'
  },
  {
    id: 'c4ai-aya-expanse-8b',
    name: 'Aya Expanse 8B',
    provider: 'Cohere',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.15, output: 0.6 },
    capabilities: ['text', 'multilingual', '23-languages'],
    category: 'text',
    isLatest: true,
    notes: 'Highly performant 8B multilingual model designed to rival monolingual performance, serves 23 languages'
  },
  {
    id: 'c4ai-aya-expanse-32b',
    name: 'Aya Expanse 32B',
    provider: 'Cohere',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.15, output: 0.6 },
    capabilities: ['text', 'multilingual', '23-languages'],
    category: 'text',
    isLatest: true,
    notes: 'Highly performant 32B multilingual model designed to rival monolingual performance, serves 23 languages'
  },
  {
    id: 'c4ai-aya-vision-8b',
    name: 'Aya Vision 8B',
    provider: 'Cohere',
    available: true,
    maxTokens: 16384,
    contextLength: 16384,
    pricing: { input: 0.15, output: 0.6 },
    capabilities: ['text', 'vision', 'multimodal', 'multilingual'],
    category: 'multimodal',
    isLatest: true,
    notes: 'State-of-the-art multimodal model excelling at language, text, and image capabilities, 8B variant focused on low latency'
  },
  {
    id: 'c4ai-aya-vision-32b',
    name: 'Aya Vision 32B',
    provider: 'Cohere',
    available: true,
    maxTokens: 16384,
    contextLength: 16384,
    pricing: { input: 0.15, output: 0.6 },
    capabilities: ['text', 'vision', 'multimodal', 'multilingual', '23-languages'],
    category: 'multimodal',
    isLatest: true,
    notes: 'State-of-the-art multimodal model excelling at language, text, and image capabilities, 32B variant focused on state-of-art multilingual performance'
  },
  {
    id: 'deepseek.r1-v1:0',
    name: 'DeepSeek-R1 (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 64000,
    contextLength: 64000,
    pricing: { input: 1.35, output: 5.4 },
    capabilities: ['text', 'reasoning', 'cot'],
    category: 'reasoning',
    isLatest: true,
    notes: 'DeepSeek-R1 reasoning model via AWS Bedrock'
  },
  {
    id: 'stability.stable-diffusion-xl-v1:0',
    name: 'Stable Diffusion XL 1.0 (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 77,
    contextLength: 77,
    pricing: { input: 0.18, output: 0.18 },
    capabilities: ['image-generation', 'creative-content'],
    category: 'image-generation',
    isLatest: true,
    notes: 'Stability AI Stable Diffusion XL via AWS Bedrock'
  },
  {
    id: 'twelvelabs.pegasus-1-2-v1:0',
    name: 'Pegasus v1.2 (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['text', 'video', 'multimodal'],
    category: 'multimodal',
    isLatest: true,
    notes: 'TwelveLabs Pegasus v1.2 via AWS Bedrock - video understanding model'
  },
  {
    id: 'twelvelabs.marengo-embed-2-7-v1:0',
    name: 'Marengo Embed v2.7 (Bedrock)',
    provider: 'AWS Bedrock',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.0, output: 0.0 },
    capabilities: ['embedding', 'multimodal'],
    category: 'embedding',
    isLatest: true,
    notes: 'TwelveLabs Marengo Embed v2.7 via AWS Bedrock - multimodal embeddings'
  },
  
  // === Mistral AI Models ===
  // Premier Models
  {
    id: 'mistral-medium-2508',
    name: 'Mistral Medium 3.1',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.4, output: 2.0 },
    capabilities: ['text', 'multimodal', 'vision', 'analysis', 'reasoning', 'enterprise'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Our frontier-class multimodal model released August 2025. Improving tone and performance.'
  },
  {
    id: 'mistral-medium-latest',
    name: 'Mistral Medium 3.1',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.4, output: 2.0 },
    capabilities: ['text', 'multimodal', 'vision', 'analysis', 'reasoning', 'enterprise'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Our frontier-class multimodal model released August 2025. Improving tone and performance.'
  },
  {
    id: 'magistral-medium-2507',
    name: 'Magistral Medium 1.1',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 40000,
    contextLength: 40000,
    pricing: { input: 2.0, output: 5.0 },
    capabilities: ['text', 'reasoning', 'thinking', 'domain-specific', 'multilingual'],
    category: 'reasoning',
    isLatest: true,
    notes: 'Our frontier-class reasoning model released July 2025.'
  },
  {
    id: 'magistral-medium-latest',
    name: 'Magistral Medium 1.1',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 40000,
    contextLength: 40000,
    pricing: { input: 2.0, output: 5.0 },
    capabilities: ['text', 'reasoning', 'thinking', 'domain-specific', 'multilingual'],
    category: 'reasoning',
    isLatest: true,
    notes: 'Our frontier-class reasoning model released July 2025.'
  },
  {
    id: 'codestral-2508',
    name: 'Codestral 2508',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 256000,
    contextLength: 256000,
    pricing: { input: 0.3, output: 0.9 },
    capabilities: ['code', 'programming', 'multilingual-code', 'fill-in-middle', 'code-correction', 'test-generation'],
    category: 'code',
    isLatest: true,
    notes: 'Our cutting-edge language model for coding released end of July 2025, specializes in low-latency, high-frequency tasks.'
  },
  {
    id: 'codestral-latest',
    name: 'Codestral 2508',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 256000,
    contextLength: 256000,
    pricing: { input: 0.3, output: 0.9 },
    capabilities: ['code', 'programming', 'multilingual-code', 'fill-in-middle', 'code-correction', 'test-generation'],
    category: 'code',
    isLatest: true,
    notes: 'Our cutting-edge language model for coding released end of July 2025, specializes in low-latency, high-frequency tasks.'
  },
  {
    id: 'voxtral-mini-2507',
    name: 'Voxtral Mini Transcribe',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.1, output: 0.1 },
    capabilities: ['audio', 'transcription', 'efficient'],
    category: 'audio',
    isLatest: true,
    notes: 'An efficient audio input model, fine-tuned and optimized for transcription purposes only.'
  },
  {
    id: 'voxtral-mini-latest',
    name: 'Voxtral Mini Transcribe',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.1, output: 0.1 },
    capabilities: ['audio', 'transcription', 'efficient'],
    category: 'audio',
    isLatest: true,
    notes: 'An efficient audio input model, fine-tuned and optimized for transcription purposes only.'
  },
  {
    id: 'devstral-medium-2507',
    name: 'Devstral Medium',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.4, output: 2.0 },
    capabilities: ['code', 'agents', 'advanced-coding', 'codebase-exploration', 'multi-file-editing'],
    category: 'code',
    isLatest: true,
    notes: 'An enterprise grade text model that excels at using tools to explore codebases, editing multiple files and power software engineering agents.'
  },
  {
    id: 'devstral-medium-latest',
    name: 'Devstral Medium',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.4, output: 2.0 },
    capabilities: ['code', 'agents', 'advanced-coding', 'codebase-exploration', 'multi-file-editing'],
    category: 'code',
    isLatest: true,
    notes: 'An enterprise grade text model that excels at using tools to explore codebases, editing multiple files and power software engineering agents.'
  },
  {
    id: 'mistral-ocr-2505',
    name: 'Mistral OCR 2505',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 1.0, output: 3.0 },
    capabilities: ['ocr', 'document-understanding', 'annotations', 'text-extraction'],
    category: 'document',
    isLatest: true,
    notes: 'Our OCR service powering our Document AI stack that enables our users to extract interleaved text and images.'
  },
  {
    id: 'mistral-ocr-latest',
    name: 'Mistral OCR 2505',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 1.0, output: 3.0 },
    capabilities: ['ocr', 'document-understanding', 'annotations', 'text-extraction'],
    category: 'document',
    isLatest: true,
    notes: 'Our OCR service powering our Document AI stack that enables our users to extract interleaved text and images.'
  },
  {
    id: 'mistral-large-2411',
    name: 'Mistral Large 2.1',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 2.0, output: 6.0 },
    capabilities: ['text', 'reasoning', 'complex-tasks', 'high-complexity'],
    category: 'text',
    isLatest: true,
    notes: 'Our top-tier large model for high-complexity tasks with the latest version released November 2024.'
  },
  {
    id: 'mistral-large-latest',
    name: 'Mistral Large 2.1',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 2.0, output: 6.0 },
    capabilities: ['text', 'reasoning', 'complex-tasks', 'high-complexity'],
    category: 'text',
    isLatest: true,
    notes: 'Our top-tier large model for high-complexity tasks with the latest version released November 2024.'
  },
  {
    id: 'pixtral-large-2411',
    name: 'Pixtral Large',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 2.0, output: 6.0 },
    capabilities: ['vision', 'multimodal', 'reasoning', 'frontier-class'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Our first frontier-class multimodal model released November 2024.'
  },
  {
    id: 'pixtral-large-latest',
    name: 'Pixtral Large',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 2.0, output: 6.0 },
    capabilities: ['vision', 'multimodal', 'reasoning', 'frontier-class'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Our first frontier-class multimodal model released November 2024.'
  },
  {
    id: 'mistral-small-2407',
    name: 'Mistral Small 2',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 32000,
    contextLength: 32000,
    pricing: { input: 0.1, output: 0.3 },
    capabilities: ['text', 'multimodal', 'multilingual', 'open-source'],
    category: 'multimodal',
    isLatest: false,
    notes: 'Our updated small version, released September 2024.'
  },
  {
    id: 'mistral-embed',
    name: 'Mistral Embed',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.1, output: 0.1 },
    capabilities: ['embedding', 'text', 'semantic'],
    category: 'embedding',
    isLatest: true,
    notes: 'Our state-of-the-art semantic for extracting representation of text extracts.'
  },
  {
    id: 'codestral-embed-2505',
    name: 'Codestral Embed',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 8192,
    contextLength: 8192,
    pricing: { input: 0.15, output: 0.15 },
    capabilities: ['embedding', 'code', 'semantic'],
    category: 'embedding',
    isLatest: true,
    notes: 'Our state-of-the-art semantic for extracting representation of code extracts.'
  },
  {
    id: 'mistral-moderation-2411',
    name: 'Mistral Moderation 24.11',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 32000,
    contextLength: 32000,
    pricing: { input: 0.1, output: 0.1 },
    capabilities: ['moderation', 'classification', 'harmful-content-detection'],
    category: 'moderation',
    isLatest: true,
    notes: 'Our moderation service that enables our users to detect harmful text content.'
  },
  {
    id: 'mistral-moderation-latest',
    name: 'Mistral Moderation 24.11',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 32000,
    contextLength: 32000,
    pricing: { input: 0.1, output: 0.1 },
    capabilities: ['moderation', 'classification', 'harmful-content-detection'],
    category: 'moderation',
    isLatest: true,
    notes: 'Our moderation service that enables our users to detect harmful text content.'
  },
  
  // Open Models
  {
    id: 'magistral-small-2507',
    name: 'Magistral Small 1.1',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 40000,
    contextLength: 40000,
    pricing: { input: 0.5, output: 1.5 },
    capabilities: ['text', 'reasoning', 'thinking', 'domain-specific', 'multilingual'],
    category: 'reasoning',
    isLatest: true,
    notes: 'Our small reasoning model released July 2025.'
  },
  {
    id: 'magistral-small-latest',
    name: 'Magistral Small 1.1',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 40000,
    contextLength: 40000,
    pricing: { input: 0.5, output: 1.5 },
    capabilities: ['text', 'reasoning', 'thinking', 'domain-specific', 'multilingual'],
    category: 'reasoning',
    isLatest: true,
    notes: 'Our small reasoning model released July 2025.'
  },
  {
    id: 'voxtral-small-2507',
    name: 'Voxtral Small',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 32000,
    contextLength: 32000,
    pricing: { input: 0.1, output: 0.1 },
    capabilities: ['audio', 'instruct', 'multimodal'],
    category: 'audio',
    isLatest: true,
    notes: 'Our first model with audio input capabilities for instruct use cases.'
  },
  {
    id: 'voxtral-small-latest',
    name: 'Voxtral Small',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 32000,
    contextLength: 32000,
    pricing: { input: 0.1, output: 0.1 },
    capabilities: ['audio', 'instruct', 'multimodal'],
    category: 'audio',
    isLatest: true,
    notes: 'Our first model with audio input capabilities for instruct use cases.'
  },
  {
    id: 'mistral-small-2506',
    name: 'Mistral Small 3.2',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.1, output: 0.3 },
    capabilities: ['text', 'multimodal', 'multilingual', 'open-source'],
    category: 'multimodal',
    isLatest: true,
    notes: 'An update to our previous small model, released June 2025.'
  },
  {
    id: 'devstral-small-2507',
    name: 'Devstral Small 1.1',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.1, output: 0.3 },
    capabilities: ['code', 'agents', 'open-source', 'codebase-exploration', 'multi-file-editing'],
    category: 'code',
    isLatest: true,
    notes: 'An update to our open source model that excels at using tools to explore codebases, editing multiple files and power software engineering agents.'
  },
  {
    id: 'devstral-small-latest',
    name: 'Devstral Small 1.1',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.1, output: 0.3 },
    capabilities: ['code', 'agents', 'open-source', 'codebase-exploration', 'multi-file-editing'],
    category: 'code',
    isLatest: true,
    notes: 'An update to our open source model that excels at using tools to explore codebases, editing multiple files and power software engineering agents.'
  },
  {
    id: 'mistral-small-2503',
    name: 'Mistral Small 3.1',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.1, output: 0.3 },
    capabilities: ['text', 'multimodal', 'multilingual', 'open-source', 'image-understanding'],
    category: 'multimodal',
    isLatest: false,
    notes: 'A new leader in the small models category with image understanding capabilities, released March 2025.'
  },
  {
    id: 'mistral-small-2501',
    name: 'Mistral Small 3',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 32000,
    contextLength: 32000,
    pricing: { input: 0.1, output: 0.3 },
    capabilities: ['text', 'multimodal', 'multilingual', 'open-source'],
    category: 'multimodal',
    isLatest: false,
    notes: 'A new leader in the small models category, released January 2025.'
  },
  {
    id: 'devstral-small-2505',
    name: 'Devstral Small 1',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.1, output: 0.3 },
    capabilities: ['code', 'agents', 'open-source', '24b-parameter'],
    category: 'code',
    isLatest: false,
    notes: 'A 24B text model, open source model that excels at using tools to explore codebases, editing multiple files and power software engineering agents.'
  },
  {
    id: 'pixtral-12b-2409',
    name: 'Pixtral 12B',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.15, output: 0.15 },
    capabilities: ['vision', 'multimodal', 'small', 'image-understanding'],
    category: 'multimodal',
    isLatest: true,
    notes: 'A 12B model with image understanding capabilities in addition to text.'
  },
  {
    id: 'pixtral-12b',
    name: 'Pixtral 12B',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.15, output: 0.15 },
    capabilities: ['vision', 'multimodal', 'small', 'image-understanding'],
    category: 'multimodal',
    isLatest: true,
    notes: 'A 12B model with image understanding capabilities in addition to text.'
  },
  {
    id: 'open-mistral-nemo-2407',
    name: 'Mistral NeMo 12B',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.15, output: 0.15 },
    capabilities: ['text', 'multilingual', 'open-source', 'best-multilingual'],
    category: 'text',
    isLatest: true,
    notes: 'Our best multilingual open source model released July 2024.'
  },
  {
    id: 'open-mistral-nemo',
    name: 'Mistral NeMo 12B',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.15, output: 0.15 },
    capabilities: ['text', 'multilingual', 'open-source', 'best-multilingual'],
    category: 'text',
    isLatest: true,
    notes: 'Our best multilingual open source model released July 2024.'
  },
  {
    id: 'mistral-nemo',
    name: 'Mistral NeMo',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 128000,
    contextLength: 128000,
    pricing: { input: 0.15, output: 0.15 },
    capabilities: ['text', 'code', 'specialized'],
    category: 'code',
    isLatest: true,
    notes: 'State-of-the-art Mistral model trained specifically for code tasks.'
  },
  {
    id: 'open-mistral-7b',
    name: 'Mistral 7B',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 32000,
    contextLength: 32000,
    pricing: { input: 0.25, output: 0.25 },
    capabilities: ['text', 'open-source', 'fast'],
    category: 'text',
    isLatest: false,
    notes: 'A 7B transformer model, fast-deployed and easily customisable.'
  },
  {
    id: 'open-mixtral-8x7b',
    name: 'Mixtral 8x7B',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 32000,
    contextLength: 32000,
    pricing: { input: 0.7, output: 0.7 },
    capabilities: ['text', 'mixture-of-experts', 'open-source'],
    category: 'text',
    isLatest: false,
    notes: 'A 7B sparse Mixture-of-Experts (SMoE). Uses 12.9B active parameters out of 45B total.'
  },
  {
    id: 'open-mixtral-8x22b',
    name: 'Mixtral 8x22B',
    provider: 'Mistral AI',
    available: true,
    maxTokens: 65000,
    contextLength: 65000,
    pricing: { input: 2.0, output: 6.0 },
    capabilities: ['text', 'mixture-of-experts', 'open-source', 'high-performance'],
    category: 'text',
    isLatest: false,
    notes: 'Most performant open model. A 22B sparse Mixture-of-Experts (SMoE). Uses only 39B active parameters out of 141B.'
  },
  // === Grok AI Models ===
  {
    id: 'grok-4-0709',
    name: 'Grok 4',
    provider: 'xAI',
    available: true,
    maxTokens: 256000,
    contextLength: 256000,
    pricing: { input: 3.0, output: 15.0 },
    capabilities: ['text', 'vision', 'reasoning', 'function-calling', 'structured-outputs'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Latest Grok 4 with reasoning, vision support coming soon. 2M TPM, 480 RPM rate limits'
  },
  {
    id: 'grok-3',
    name: 'Grok 3',
    provider: 'xAI',
    available: true,
    maxTokens: 131072,
    contextLength: 131072,
    pricing: { input: 3.0, output: 15.0 },
    capabilities: ['text', 'vision', 'function-calling', 'structured-outputs'],
    category: 'multimodal',
    isLatest: false,
    notes: 'Standard Grok 3 model. 600 RPM rate limits'
  },
  {
    id: 'grok-3-mini',
    name: 'Grok 3 Mini',
    provider: 'xAI',
    available: true,
    maxTokens: 131072,
    contextLength: 131072,
    pricing: { input: 0.3, output: 0.5 },
    capabilities: ['text', 'vision', 'function-calling', 'structured-outputs'],
    category: 'multimodal',
    isLatest: false,
    notes: 'Cost-effective Grok 3 Mini. 480 RPM rate limits'
  },
  {
    id: 'grok-2-image-1212',
    name: 'Grok 2 Image',
    provider: 'xAI',
    available: true,
    maxTokens: 0,
    contextLength: 0,
    pricing: { input: 0.07, output: 0.07 },
    capabilities: ['image-generation'],
    category: 'image',
    isLatest: true,
    notes: 'Grok 2 image generation model. $0.07 per image, 300 RPM rate limits'
  },
  // === Meta Llama 4 Models ===
  {
    id: 'llama-4-scout',
    name: 'Llama 4 Scout',
    provider: 'Meta',
    available: true,
    maxTokens: 10000000,
    contextLength: 10000000,
    pricing: { input: 0.19, output: 0.49 },
    capabilities: ['text', 'vision', 'multimodal', 'long-context', 'multilingual', 'image-grounding'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Class-leading natively multimodal model with superior text and visual intelligence, single H100 GPU efficiency, and 10M context window for seamless long document analysis'
  },
  {
    id: 'llama-4-maverick',
    name: 'Llama 4 Maverick',
    provider: 'Meta',
    available: true,
    maxTokens: 10000000,
    contextLength: 10000000,
    pricing: { input: 0.19, output: 0.49 },
    capabilities: ['text', 'vision', 'multimodal', 'long-context', 'multilingual', 'image-grounding', 'fast-responses'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Industry-leading natively multimodal model for image and text understanding with groundbreaking intelligence and fast responses at a low cost'
  },
  {
    id: 'llama-4-behemoth-preview',
    name: 'Llama 4 Behemoth Preview',
    provider: 'Meta',
    available: true,
    maxTokens: 10000000,
    contextLength: 10000000,
    pricing: { input: 0.19, output: 0.49 },
    capabilities: ['text', 'vision', 'multimodal', 'long-context', 'multilingual', 'image-grounding', 'teacher-model'],
    category: 'multimodal',
    isLatest: true,
    notes: 'Early preview of the Llama 4 teacher model used to distill Llama 4 Scout and Llama 4 Maverick. Still in training phase'
  }
];

export const getModelsByProvider = (provider?: string): ModelInfo[] => {
  if (!provider) {
    return AVAILABLE_MODELS;
  }
  return AVAILABLE_MODELS.filter(model => 
    model.provider.toLowerCase().includes(provider.toLowerCase())
  );
};

export const getLatestModels = (): ModelInfo[] => {
  return AVAILABLE_MODELS.filter(model => model.isLatest);
};

export const getModelsByCategory = (category?: string): ModelInfo[] => {
  if (!category) {
    return AVAILABLE_MODELS;
  }
  return AVAILABLE_MODELS.filter(model => 
    model.category.toLowerCase() === category.toLowerCase()
  );
};

export const searchModels = (query: string): ModelInfo[] => {
  const lowerQuery = query.toLowerCase();
  return AVAILABLE_MODELS.filter(model => 
    model.name.toLowerCase().includes(lowerQuery) ||
    model.id.toLowerCase().includes(lowerQuery) ||
    model.provider.toLowerCase().includes(lowerQuery) ||
    model.capabilities.some(cap => cap.toLowerCase().includes(lowerQuery))
  );
}; 